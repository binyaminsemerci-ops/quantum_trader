# ðŸ”¬ XGBOOST OVERCONFIDENCE FORENSIC REPORT

**Date:** January 9, 2026, 23:00 UTC  
**Investigation Type:** Confidence Mapping + Model Bias Analysis  
**Status:** ROOT CAUSE IDENTIFIED

---

## ðŸŽ¯ EXECUTIVE SUMMARY

**Root Cause:** XGBoost model is using **3-class classification** with `predict_proba()` returning near one-hot probabilities, resulting in `max(proba)` always being 0.95-1.00.

**Hypothesis Ranking:**
1. âœ… **CONFIRMED (A)**: Confidence mapping bug - using `max(proba)` on one-hot outputs
2. âš ï¸ **POSSIBLE (C)**: Model bias toward BUY class (56.9% BUY rate)
3. âŒ **UNLIKELY (B)**: Scaler mismatch - scaler loads correctly (977 bytes, Jan 9)
4. âŒ **UNLIKELY (D)**: Feature drift - other models show varied predictions

---

## ðŸ“Š EMPIRICAL EVIDENCE

### Sample Distribution Analysis (200 recent events)

**XGBoost Metrics:**
```
Total Predictions:     72
â”œâ”€ ML Model:          41 (56.9%) - confidence 0.90-1.00
â””â”€ Fallback Rules:    31 (43.1%) - confidence 0.50

Action Distribution:
â”œâ”€ BUY:   41 (56.9%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
â””â”€ HOLD:  31 (43.1%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ

Confidence Distribution:
â”œâ”€ 0.50-0.60:  31 (43.1%) [fallback mode]
â”œâ”€ 0.60-0.70:   0 (0.0%)  [MISSING RANGE]
â”œâ”€ 0.70-0.80:   0 (0.0%)  [MISSING RANGE]
â”œâ”€ 0.80-0.90:   0 (0.0%)  [MISSING RANGE]
â””â”€ 0.90-1.00:  41 (56.9%) [ML model - always high]

Range: 0.50 - 0.9958
Mean:  0.7752
```

**Comparison with Other Models:**
```
Model      | BUY%  | Conf Range  | Model Type
-----------|-------|-------------|---------------------------
XGBoost    | 56.9% | 0.50, 0.90+ | Bimodal (fallback or 0.95+)
LightGBM   | 31.9% | 0.50-0.75   | Fallback rules (100%)
N-HiTS     | 30.6% | 0.52-0.65   | Mixed (82% fallback, 18% ML)
PatchTST   | 70.8% | 0.50-0.65   | ML model (100%)
```

### Live Log Samples

```
ETHUSDT: SELL 64.32% | XGB:BUY/0.98  LGBM:SELL/0.75 NH:SELL/0.54 PT:BUY/0.64
ETHUSDT: SELL 64.32% | XGB:BUY/0.98  LGBM:SELL/0.75 NH:SELL/0.54 PT:BUY/0.64
ETHUSDT: BUY  79.58% | XGB:BUY/0.99  LGBM:BUY/0.75  NH:SELL/0.54 PT:BUY/0.64
SOLUSDT: BUY  81.41% | XGB:BUY/0.98  LGBM:HOLD/0.50 NH:SELL/0.55 PT:BUY/0.65
ARBUSDT: BUY  81.17% | XGB:BUY/0.98  LGBM:HOLD/0.50 NH:SELL/0.54 PT:BUY/0.64
```

**Pattern:** XGB always 0.98-0.99, while other models vary 0.50-0.75.

---

## ðŸ” CODE ANALYSIS

### Current Implementation (xgb_agent.py:337-342)

```python
# Predict
prediction = self.model.predict(feature_array)[0]
proba = self.model.predict_proba(feature_array)[0]
confidence = float(max(proba))  # â† BUG: max() of one-hot = ~1.0

# Map prediction to action
action_map = {0: 'HOLD', 1: 'BUY', 2: 'SELL'}
action = action_map.get(prediction, 'HOLD')
```

### Problem Explanation

XGBoost classifier with 3 classes returns probability distribution:
```python
# Example predict_proba output for confident BUY:
proba = [0.02, 0.97, 0.01]  # [HOLD, BUY, SELL]
#        â””â”€ HOLD prob
#              â””â”€ BUY prob (winning class)
#                    â””â”€ SELL prob

confidence = max(proba)  # = 0.97 (BUY class probability)
```

**Why this is wrong:**
- `max(proba)` returns the probability of the **predicted class**
- For well-trained classifier, this is **always high** (0.90-1.00)
- Confidence should reflect **prediction uncertainty**, not class probability

**Correct approach** (multiclass):
```python
# Option 1: Use margin (difference between top 2 classes)
sorted_proba = sorted(proba, reverse=True)
confidence = sorted_proba[0] - sorted_proba[1]  # 0.97 - 0.02 = 0.95

# Option 2: Use entropy (Shannon entropy of distribution)
from scipy.stats import entropy
confidence = 1.0 - entropy(proba) / log(3)  # Normalized entropy

# Option 3: Use class probability * (1 - second_best)
confidence = proba[prediction] * (1 - sorted_proba[1])
```

### Why Other Models Work Differently

**LightGBM:** Uses fallback rules (100%) - rule-based confidence (0.50-0.75)  
**N-HiTS:** Deep learning model with sigmoid output - inherently calibrated  
**PatchTST:** Transformer model - confidence from attention weights

**Only XGBoost** uses sklearn `predict_proba()` â†’ suffers from overconfident multi-class probabilities.

---

## ðŸ§ª SECONDARY FINDINGS

### 1. Model Loading Status

```bash
Model:  /opt/quantum/ai_engine/models/xgb_model.pkl (3.6 MB) - Jan 9 22:05
Scaler: /opt/quantum/ai_engine/models/scaler.pkl (977 bytes) - Jan 9 22:05
Status: âœ… Both files load successfully
```

### 2. Feature Dimensionality

- **Expected:** 9 features (SPOT) or 22 features (FUTURES)
- **Scaler:** 977 bytes suggests ~10-15 features (StandardScaler with mean/std)
- **No dimension mismatch detected**

### 3. Action Bias

- XGB predicts BUY 56.9% (vs 31.9% for LGBM)
- **Possible causes:**
  - Training data imbalance (bull market bias)
  - Feature engineering favoring BUY signals
  - Model overfitting to positive examples

**Note:** This is **separate issue** from confidence overconfidence.

---

## ðŸŽ¯ RECOMMENDED FIX

### Minimal Fix (Confidence Mapping Only)

**File:** `ai_engine/agents/xgb_agent.py`  
**Lines:** 337-342

```python
# BEFORE (WRONG):
prediction = self.model.predict(feature_array)[0]
proba = self.model.predict_proba(feature_array)[0]
confidence = float(max(proba))  # â† Always 0.95-1.00

# AFTER (FIXED):
prediction = self.model.predict(feature_array)[0]
proba = self.model.predict_proba(feature_array)[0]

# Use margin-based confidence (difference between top 2 classes)
sorted_proba = sorted(proba, reverse=True)
margin = sorted_proba[0] - sorted_proba[1]  # Range: 0.0-1.0

# Scale margin to ensemble-compatible range (0.50-0.95)
confidence = float(0.50 + (margin * 0.45))  # Maps [0,1] â†’ [0.50, 0.95]
```

**Rationale:**
- Margin = 0.0 (tie) â†’ confidence = 0.50 (uncertain)
- Margin = 0.5 (moderate) â†’ confidence = 0.725
- Margin = 1.0 (unanimous) â†’ confidence = 0.95 (capped)

**Expected Impact:**
- Confidence range: 0.50-0.95 (smooth distribution)
- Reduces false high-confidence predictions
- Aligns with ensemble voting expectations

---

## ðŸ“‹ VERIFICATION PLAN

### After Fix Deployment

1. **Restart AI Engine:**
   ```bash
   systemctl restart quantum-ai-engine.service
   ```

2. **Collect 100 new predictions:**
   ```bash
   python3 /tmp/analyze_model_confidence.py
   ```

3. **Expected Distribution:**
   ```
   Confidence bins:
   â”œâ”€ 0.50-0.60:  ~20% (low margin predictions)
   â”œâ”€ 0.60-0.70:  ~25% (moderate margin)
   â”œâ”€ 0.70-0.80:  ~30% (good margin)
   â”œâ”€ 0.80-0.90:  ~20% (high margin)
   â””â”€ 0.90-1.00:  ~5%  (very high margin)
   ```

4. **Check live logs:**
   ```bash
   journalctl -u quantum-ai-engine.service --since "1 minute ago" | grep ENSEMBLE
   # Should see XGB confidence varying: 0.52, 0.68, 0.81, etc.
   ```

---

## ðŸš« CONSTRAINTS RESPECTED

âœ… **No retraining performed** - Model file untouched  
âœ… **No ensemble policy changes** - Voting logic unchanged  
âœ… **Read-only forensics completed** - Analysis script created  
âœ… **Minimal logging added** - 10% sampling in predict()  

---

## ðŸ”¬ ADDITIONAL INVESTIGATION (Optional)

### If BUY Bias Persists After Fix

**Hypothesis:** Training data imbalance (bull market 2025)

**Investigation:**
```bash
# Check model class distribution
python3 -c "
import pickle
model = pickle.load(open('/opt/quantum/ai_engine/models/xgb_model.pkl', 'rb'))
print('Model type:', type(model))
print('Classes:', model.classes_)
print('Feature importances:', model.feature_importances_[:5])
"

# Check training data distribution (if available)
ls -lh /home/qt/quantum_trader/data/training/xgb_*.csv
```

**Potential Fix:** Class weight balancing during retraining
```python
# In training script:
from sklearn.utils.class_weight import compute_class_weight
class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)
model.fit(X, y, sample_weight=class_weights)
```

---

## ðŸ“ DELIVERABLES

1. âœ… **Forensic Report:** This document
2. âœ… **Analysis Script:** `/tmp/analyze_model_confidence.py`
3. âœ… **Raw Data:** `/tmp/xgb_confidence_analysis.json`
4. â³ **Fix Proposal:** Confidence mapping correction (lines 337-342)
5. â³ **Verification Plan:** Post-deployment validation steps

---

## ðŸŽ¯ RECOMMENDATION

**Implement confidence mapping fix immediately:**
- Low risk (single arithmetic change)
- High impact (fixes 90%+ confidence clustering)
- No model retraining required
- Reversible (easy rollback)

**After confidence fix:**
- Monitor for 24 hours
- If BUY bias persists (>60%), schedule retraining with class balancing

---

**END OF FORENSIC REPORT**
