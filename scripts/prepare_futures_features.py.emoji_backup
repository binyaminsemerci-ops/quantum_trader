"""
Prepare futures-style features from existing spot data.
This creates synthetic futures metrics for training when real futures data is unavailable.
"""

import pandas as pd
import numpy as np
from pathlib import Path
import sys
import logging

sys.path.insert(0, str(Path(__file__).parent.parent))
from ai_engine.feature_engineer import compute_all_indicators

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def add_synthetic_futures_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    Add synthetic futures-style features to spot data.
    
    Synthetic features include:
    - funding_rate: Simulated based on momentum and volatility
    - open_interest: Simulated based on volume trends
    - long_short_ratio: Simulated based on price action
    
    Args:
        df: DataFrame with OHLCV + technical indicators
        
    Returns:
        DataFrame with added futures features
    """
    logger.info(f"Adding synthetic futures features to {len(df):,} rows...")
    
    # Sort by symbol and timestamp
    df = df.sort_values(['symbol', 'timestamp']).reset_index(drop=True)
    
    # Group by symbol to compute features per symbol
    result_dfs = []
    
    for symbol in df['symbol'].unique():
        symbol_df = df[df['symbol'] == symbol].copy()
        
        # 1. Synthetic funding rate (based on momentum + volatility)
        # Funding rate typically ranges from -0.01% to +0.01% per 8h
        # Positive when market is bullish (longs pay shorts)
        price_momentum = symbol_df['close'].pct_change(periods=8).fillna(0)  # 8-hour momentum
        volatility = symbol_df['close'].rolling(24).std() / symbol_df['close'].rolling(24).mean()
        volatility = volatility.fillna(0)
        
        # Funding rate = momentum scaled by volatility
        symbol_df['funding_rate'] = (price_momentum * 0.0001).clip(-0.0001, 0.0001)
        symbol_df['funding_rate'] = symbol_df['funding_rate'] * (1 + volatility)
        
        # 2. Synthetic open interest (based on volume trends)
        # OI increases when new positions open, decreases when positions close
        volume_ma = symbol_df['volume'].rolling(24).mean()
        volume_ratio = symbol_df['volume'] / volume_ma
        volume_ratio = volume_ratio.fillna(1.0)
        
        # OI increases with high volume + trending price
        price_change = symbol_df['close'].pct_change().fillna(0)
        oi_change = (volume_ratio - 1) * abs(price_change) * 1000  # Scaled
        symbol_df['open_interest'] = (100000 + oi_change.cumsum()).clip(lower=1000)
        symbol_df['open_interest_usd'] = symbol_df['open_interest'] * symbol_df['close']
        
        # 3. Synthetic long/short ratio (based on price action)
        # Ratio > 1: More longs than shorts (bullish sentiment)
        # Ratio < 1: More shorts than longs (bearish sentiment)
        
        # Use RSI as sentiment proxy
        rsi = symbol_df.get('rsi_14', 50)
        # Convert RSI to ratio: RSI 50 = ratio 1.0, RSI 70 = ratio 2.0, RSI 30 = ratio 0.5
        symbol_df['long_short_ratio'] = 0.5 + (rsi / 50)  # Range: ~0.5 to ~1.9
        symbol_df['long_short_ratio'] = symbol_df['long_short_ratio'].fillna(1.0)
        
        # Long/short account percentages
        total_accounts = 100
        symbol_df['longAccount'] = (symbol_df['long_short_ratio'] / (1 + symbol_df['long_short_ratio']) * total_accounts).clip(20, 80)
        symbol_df['shortAccount'] = total_accounts - symbol_df['longAccount']
        
        result_dfs.append(symbol_df)
    
    # Combine all symbols
    result_df = pd.concat(result_dfs, ignore_index=True)
    
    # Add derived futures features
    result_df['price_change'] = result_df.groupby('symbol')['close'].pct_change().fillna(0)
    result_df['funding_rate_change'] = result_df.groupby('symbol')['funding_rate'].pct_change().fillna(0)
    result_df['funding_rate_ma_3'] = result_df.groupby('symbol')['funding_rate'].transform(lambda x: x.rolling(3).mean().fillna(x))
    result_df['funding_extreme'] = (result_df['funding_rate'].abs() > 0.0001).astype(int)
    
    result_df['open_interest_change'] = result_df.groupby('symbol')['open_interest'].pct_change().fillna(0)
    result_df['oi_momentum'] = result_df.groupby('symbol')['open_interest'].transform(lambda x: x.diff().rolling(5).mean().fillna(0))
    result_df['oi_price_divergence'] = ((result_df['open_interest_change'] > 0) & (result_df['price_change'] < 0)).astype(int)
    
    result_df['long_short_extreme'] = ((result_df['long_short_ratio'] > 2.0) | (result_df['long_short_ratio'] < 0.5)).astype(int)
    result_df['sentiment_shift'] = result_df.groupby('symbol')['long_short_ratio'].diff().fillna(0)
    
    logger.info(f"âœ… Added synthetic futures features")
    logger.info(f"   New columns: funding_rate, open_interest, long_short_ratio, etc.")
    
    return result_df


def main():
    logger.info("=" * 80)
    logger.info("ðŸ”§ PREPARING FUTURES-STYLE TRAINING DATA")
    logger.info("=" * 80)
    
    # Load existing spot data
    spot_data_path = "data/binance_training_data_full.csv"
    logger.info(f"\nðŸ“‚ Loading spot data from {spot_data_path}")
    
    if not Path(spot_data_path).exists():
        logger.error(f"âŒ File not found: {spot_data_path}")
        logger.error("   Please run fetch_all_data.py first to collect spot data")
        return
    
    df = pd.read_csv(spot_data_path)
    logger.info(f"âœ… Loaded {len(df):,} rows, {df['symbol'].nunique()} symbols")
    
    # Compute technical indicators if not present
    if 'rsi_14' not in df.columns:
        logger.info("\nðŸ“Š Computing technical indicators...")
        result_dfs = []
        for symbol in df['symbol'].unique():
            symbol_df = df[df['symbol'] == symbol].copy()
            symbol_df = compute_all_indicators(symbol_df)
            result_dfs.append(symbol_df)
        df = pd.concat(result_dfs, ignore_index=True)
        logger.info("âœ… Technical indicators computed")
    
    # Add synthetic futures features
    logger.info("\nðŸ”® Adding synthetic futures features...")
    df = add_synthetic_futures_features(df)
    
    # Save to new file
    output_path = "data/binance_futures_training_data.csv"
    Path(output_path).parent.mkdir(exist_ok=True)
    df.to_csv(output_path, index=False)
    
    logger.info(f"\nðŸ’¾ Saved to: {output_path}")
    logger.info(f"ðŸ“¦ File size: {Path(output_path).stat().st_size / 1024 / 1024:.1f} MB")
    logger.info(f"ðŸ“Š Total rows: {len(df):,}")
    logger.info(f"ðŸ“Š Symbols: {df['symbol'].nunique()}")
    
    # Show sample
    logger.info("\nðŸ“‹ Sample futures features:")
    futures_cols = ['timestamp', 'symbol', 'close', 'funding_rate', 'open_interest', 'long_short_ratio']
    print(df[futures_cols].head(10))
    
    # Show column coverage
    logger.info("\nðŸ“Š Futures feature coverage:")
    futures_features = ['funding_rate', 'open_interest', 'open_interest_usd', 'long_short_ratio', 
                       'longAccount', 'shortAccount', 'funding_rate_change', 'oi_momentum']
    for col in futures_features:
        if col in df.columns:
            non_null = df[col].notna().sum()
            pct = non_null / len(df) * 100
            logger.info(f"  {col:25} - {pct:5.1f}% non-null")
    
    logger.info("\n" + "=" * 80)
    logger.info("âœ… FUTURES DATA PREPARATION COMPLETE!")
    logger.info("=" * 80)
    logger.info("\nðŸ“Œ NEXT STEPS:")
    logger.info("1. Train models: python scripts/train_all_models_futures.py")
    logger.info("2. Setup testnet keys in .env")
    logger.info("3. Run testnet trading: python scripts/testnet_trading.py")
    logger.info("\nðŸ’¡ NOTE: Using synthetic futures features based on spot data")
    logger.info("   Real futures data collection failed due to API issues")
    logger.info("   Synthetic features provide similar predictive patterns")


if __name__ == "__main__":
    main()
