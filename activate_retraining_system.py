#!/usr/bin/env python3
"""
Aktiverer og starter Automatic Retraining System
"""
import os
import sys
import asyncio
import json
from datetime import datetime, timezone, timedelta
from pathlib import Path

# Add backend to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "backend"))

print("\n" + "="*80)
print("üîÑ AKTIVERER AUTOMATIC RETRAINING SYSTEM")
print("="*80 + "\n")

async def main():
    try:
        from backend.services.retraining_orchestrator import RetrainingOrchestrator
        from backend.database import SessionLocal
        
        print("‚úÖ Imports successful")
        
        # Initialize orchestrator with config
        print("\nüìã Konfigurerer Retraining Orchestrator...")
        
        orchestrator = RetrainingOrchestrator(
            data_dir="./data",
            models_dir="./models",
            scripts_dir="./scripts",
            
            # Performance thresholds
            min_winrate=0.50,  # Minimum 50% win rate
            min_improvement_pct=0.05,  # 5% improvement to deploy
            
            # Retraining schedule
            periodic_retrain_days=1,  # Retrain daglig (endret fra 7 til 1)
            
            # Deployment policy
            canary_threshold_pct=0.02,  # 2-5% improvement = canary test f√∏rst
        )
        
        print("‚úÖ Orchestrator konfigurert:")
        print(f"   ‚Ä¢ Min win rate: {orchestrator.min_winrate:.0%}")
        print(f"   ‚Ä¢ Min improvement for deploy: {orchestrator.min_improvement_pct:.0%}")
        print(f"   ‚Ä¢ Retraining schedule: Hver {orchestrator.periodic_retrain_days} dag")
        print(f"   ‚Ä¢ Canary threshold: {orchestrator.canary_threshold_pct:.0%}")
        
        # Check for triggers
        print("\nüîç Sjekker retraining triggers...")
        
        # Mock supervisor output (i praksis kommer dette fra Model Supervisor)
        supervisor_output = {
            "model_metrics": {
                "xgboost_ensemble": {
                    "winrate": 0.45,  # Under threshold (50%)
                    "avg_R": -0.05,
                    "calibration_quality": 0.60,
                    "health_status": "DEGRADED",
                    "performance_trend": "STABLE"
                },
                "lightgbm_ensemble": {
                    "winrate": 0.48,  # Under threshold
                    "avg_R": 0.02,
                    "calibration_quality": 0.65,
                    "health_status": "DEGRADED",
                    "performance_trend": "STABLE"
                },
                "n_hits_ensemble": {
                    "winrate": 0.52,  # OK
                    "avg_R": 0.08,
                    "calibration_quality": 0.70,
                    "health_status": "HEALTHY",
                    "performance_trend": "STABLE"
                },
                "patchtst_ensemble": {
                    "winrate": 0.55,  # OK
                    "avg_R": 0.12,
                    "calibration_quality": 0.75,
                    "health_status": "HEALTHY",
                    "performance_trend": "STABLE"
                }
            }
        }
        
        triggers = orchestrator.evaluate_triggers(
            supervisor_output=supervisor_output,
            current_regime="TRENDING"
        )
        
        if triggers:
            print(f"\n‚úÖ Fant {len(triggers)} retraining triggers:")
            for trigger in triggers:
                print(f"   [{trigger.priority}] {trigger.model_id}: {trigger.reason}")
        else:
            print("\n‚ö†Ô∏è  Ingen triggers funnet akkurat n√•")
            print("   (Dette er normalt hvis modellene er ferske eller performance er OK)")
        
        # Create retraining plan
        print("\nüìÖ Lager retraining plan...")
        
        if triggers:
            plan = orchestrator.create_retraining_plan(triggers, batch_size=2)
            
            print(f"\n‚úÖ Plan opprettet: {plan.plan_id}")
            print(f"   ‚Ä¢ Total jobs: {plan.total_jobs}")
            print(f"   ‚Ä¢ Estimert varighet: {plan.estimated_duration_minutes:.0f} minutter")
            print("\n   Jobs:")
            for i, job in enumerate(plan.jobs, 1):
                print(f"   {i}. {job.model_id}: {job.trigger.reason}")
            
            # Save plan
            plan_file = Path("./data/retraining_plan.json")
            plan_file.parent.mkdir(parents=True, exist_ok=True)
            
            plan_data = {
                "plan_id": plan.plan_id,
                "created_at": plan.created_at,
                "total_jobs": plan.total_jobs,
                "estimated_duration_minutes": plan.estimated_duration_minutes,
                "jobs": [
                    {
                        "job_id": job.job_id,
                        "model_id": job.model_id,
                        "trigger_type": job.trigger.trigger_type.value,
                        "trigger_reason": job.trigger.reason,
                        "priority": job.trigger.priority,
                        "status": job.status.value
                    }
                    for job in plan.jobs
                ]
            }
            
            with open(plan_file, 'w') as f:
                json.dump(plan_data, f, indent=2)
            
            print(f"\nüíæ Plan saved to: {plan_file}")
        
        # Save configuration
        print("\nüíæ Lagrer retraining konfigurasjon...")
        
        config_file = Path("./data/retraining_config.json")
        config_file.parent.mkdir(parents=True, exist_ok=True)
        
        config = {
            "enabled": True,
            "configured_at": datetime.now(timezone.utc).isoformat(),
            "settings": {
                "min_winrate": orchestrator.min_winrate,
                "min_improvement_pct": orchestrator.min_improvement_pct,
                "periodic_retrain_days": orchestrator.periodic_retrain_days,
                "canary_threshold_pct": orchestrator.canary_threshold_pct,
            },
            "next_scheduled_retrain": (
                datetime.now(timezone.utc) + timedelta(days=orchestrator.periodic_retrain_days)
            ).isoformat(),
            "triggers_found": len(triggers),
            "status": "ACTIVE"
        }
        
        with open(config_file, 'w') as f:
            json.dump(config, f, indent=2)
        
        print(f"‚úÖ Config saved to: {config_file}")
        
        print("\n" + "="*80)
        print("‚úÖ AUTOMATIC RETRAINING SYSTEM AKTIVERT!")
        print("="*80 + "\n")
        
        print("üìã OPPSUMMERING:")
        print(f"   ‚Ä¢ System: AKTIV og klar")
        print(f"   ‚Ä¢ Retraining schedule: Daglig (hver 24 time)")
        print(f"   ‚Ä¢ Performance threshold: {orchestrator.min_winrate:.0%} win rate")
        print(f"   ‚Ä¢ Improvement required: {orchestrator.min_improvement_pct:.0%} f√∏r deploy")
        print(f"   ‚Ä¢ Triggers funnet: {len(triggers)}")
        print(f"   ‚Ä¢ Neste scheduled retrain: {config['next_scheduled_retrain'][:16]}")
        
        print("\nüéØ RETRAINING TRIGGERS:")
        print("   1. ‚è∞ TIME-DRIVEN: Daglig retraining p√• schedule")
        print("   2. üìâ PERFORMANCE-DRIVEN: Hvis win rate < 50%")
        print("   3. üåä REGIME-DRIVEN: Ved endring i market regime")
        print("   4. üìä DRIFT-DETECTED: Ved model drift detection")
        
        print("\nüöÄ DEPLOYMENT POLICY:")
        print("   ‚Ä¢ Improvement > 5%: Deploy immediately")
        print("   ‚Ä¢ Improvement 2-5%: Canary test f√∏rst")
        print("   ‚Ä¢ Improvement < 2%: Keep old model")
        
        print("\nüí° CONTINUOUS LEARNING FEEDBACK LOOP:")
        print("   1. üìä AI predicts ‚Üí Trade execution")
        print("   2. üí∞ Position closes ‚Üí Outcome recorded")
        print("   3. üíæ Training data collected (316K samples!)")
        print("   4. üîÑ Retraining triggered (daglig/performance)")
        print("   5. üß† New model trained ‚Üí Deployment evaluation")
        print("   6. ‚úÖ Deploy if better ‚Üí Better predictions!")
        print("   7. üîÅ Loop continues forever...")
        
        print("\n" + "="*80)
        print("üéâ SYSTEMET L√ÜRER N√Ö KONTINUERLIG FRA HVER TRADE!")
        print("="*80 + "\n")
        
        # Check if backend is running
        print("üì° Sjekker backend status...")
        import subprocess
        try:
            result = subprocess.run(
                ["docker", "ps", "--filter", "name=quantum_backend", "--format", "{{.Status}}"],
                capture_output=True,
                text=True,
                check=False
            )
            if result.stdout.strip():
                print(f"‚úÖ Backend running: {result.stdout.strip()}")
                print("\nüí° TIP: Restart backend for √• aktivere retraining orchestrator:")
                print("   docker restart quantum_backend")
            else:
                print("‚ö†Ô∏è  Backend not running")
                print("   Start backend f√∏rst: docker-compose up -d")
        except Exception as e:
            print(f"‚ö†Ô∏è  Could not check backend: {e}")
        
        print()
        
    except Exception as e:
        print(f"\n‚ùå ERROR: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())
