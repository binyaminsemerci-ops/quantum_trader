# P2.8A Apply Shadow Observability - Documentation

## Overview

**P2.8A Apply Heat Observer** is a shadow-only observability layer that reads HeatBridge cache for each Apply plan and emits observed events to a dedicated stream. This provides complete transparency into heat gate integration without ANY execution impact.

### Purpose

- **Observability**: Track how often Apply sees heat decisions from HeatBridge (P2.6/P2.7)
- **Validation**: Verify HeatBridge cache is populated and accessible
- **Shadow-Only**: Zero impact on Apply decisions, plan execution, or order placement
- **Fail-Open**: Redis errors, missing heat keys, or observer failures never block Apply processing

---

## Observation Points

P2.8A.1 observes heat at **two distinct points** in Apply's execution flow:

### 1. Plan Creation (`create_apply_plan`)

**Location**: `microservices/apply_layer/main.py` → `create_apply_plan()` method  
**Timing**: After plan object is created, before return  
**Trigger**: Harvest proposal processing (normal Apply flow)  
**Use Case**: Standard shadow observation during normal operations

**Flow**:
```
Harvest → Apply reads proposal → create_apply_plan() → [Observer called here] → return plan
```

### 2. Apply.Plan Consumption (`process_reconcile_close_stream`)

**Location**: `microservices/apply_layer/main.py` → `process_reconcile_close_stream()` method  
**Timing**: After parsing plan from `quantum:stream:reconcile.close`, before execution  
**Trigger**: RECONCILE_CLOSE plans or direct stream injection (for testing)  
**Use Case**: Deterministic proof testing and reconciliation flows

**Flow**:
```
quantum:stream:reconcile.close → Apply consumes → [Observer called here] → execute_reconcile_close()
```

**Important**: Apply **publishes** to `quantum:stream:apply.plan` but **consumes** from `quantum:stream:reconcile.close`. For deterministic testing, inject into reconcile.close, not apply.plan.

**Why Two Points?**

- **Plan Creation**: Captures standard flow where Apply creates plans from harvest proposals
- **Apply.Plan Consumption**: Enables deterministic testing with known `plan_id` values and captures reconciliation scenarios
- **Deduplication**: Same dedupe key prevents double-emission if plan appears in both flows

---

## ZERO Execution Impact Guarantee

P2.8A is designed with the following ironclad principles:

1. **Never blocks**: All operations are fail-open; errors are logged and processing continues
2. **Never changes decisions**: Apply's decision logic is completely unchanged
3. **Never modifies plans**: Plan creation, execution, and results are unaffected
4. **Never touches orders**: No interaction with exchange APIs or order placement
5. **Minimal overhead**: Single Redis HGETALL + XADD per plan (~5-10ms total)

**Implementation proof**:
- Heat observer is called AFTER plan creation is complete (both observation points)
- Observer wrapped in try/except catch-all to protect Apply
- All observer errors are logged but don't propagate
- If P28_HEAT_OBS_ENABLED=false, observer is completely skipped (zero overhead)

---

## Architecture

### Input: HeatBridge Cache (Read-Only)

**Key**: `quantum:harvest:heat:by_plan:{plan_id}`  
**Type**: HASH  
**Source**: P2.7 HeatBridge service (consumes P2.6 heat decisions)

**Fields** (all optional for observer):
- `ts_epoch` - Timestamp of heat decision
- `symbol` - Trading symbol
- `plan_id` - Harvest plan ID
- `in_action` - Original action from Apply
- `out_action` - Modified action (if any)
- `heat_level` - cold | warm | hot | unknown
- `heat_score` - Heat score (0.0-1.0)
- `heat_action` - NONE | DOWNGRADE_FULL_TO_PARTIAL | HOLD_CLOSE
- `recommended_partial` - Partial close size (0.25/0.50/0.75)
- `reason` - Heat decision reason
- `mode` - "shadow"
- `debug_json` - Debug context

### Output: Observed Stream

**Stream**: `quantum:stream:apply.heat.observed`  
**Type**: Redis Stream (XADD)  
**Max Length**: 10000 (MAXLEN ~ 10000)

**Message Schema** (15 fields):

```json
{
  "ts_epoch": 1735689600,                         // Observer timestamp (now)
  "plan_id": "a4f3b8c2d1e5f6a7",                  // Apply plan ID
  "symbol": "BTCUSDT",                             // Trading symbol
  "apply_component": "apply",                      // Always "apply" (for future multi-component obs)
  "obs_point": "create_apply_plan",                // Observation point (create_apply_plan | reconcile_close_consume)
  "heat_found": 1,                                 // 0 or 1 (heat key exists)
  "heat_ts_epoch": 1735689550,                     // Timestamp from heat key (or empty)
  "heat_level": "warm",                            // cold|warm|hot|unknown|empty
  "heat_score": 0.45,                              // Heat score (or empty)
  "heat_action": "DOWNGRADE_FULL_TO_PARTIAL",     // Heat action (or empty)
  "heat_out_action": "PARTIAL_50_PROPOSED",       // Modified action (or empty)
  "heat_recommended_partial": 0.5,                 // Partial size (or empty)
  "heat_reason": "ok",                             // ok|missing|redis_error|parse_error
  "apply_decision": "EXECUTE",                     // Apply decision (EXECUTE/SKIP/BLOCKED/UNKNOWN)
  "debug_json": "{\"in_action\":\"FULL_CLOSE_PROPOSED\",\"mode\":\"shadow\"}"  // Limited debug context
}
```

**obs_point Values**:
- `create_apply_plan` - Event observed during plan creation (standard harvest flow)
- `reconcile_close_consume` - Event observed during reconcile.close consumption (reconciliation flow)

### Deduplication

To prevent duplicate observations if Apply reprocesses the same plan, deduplication is **per observation point**:

**Dedupe Key**: `quantum:dedupe:p28:{obs_point}:{plan_id}`  
**Type**: STRING  
**Value**: "1"  
**TTL**: 600s (10 minutes, configurable via P28_DEDUPE_TTL_SEC)

**Why per obs_point?**
- Same `plan_id` may legitimately appear in both flows (plan creation + reconcile)
- Each observation point provides different context (creation vs execution)
- Prevents hiding legitimate events from different processing stages

**Behavior**:
- First observation at specific obs_point: Dedupe key doesn't exist → emit observed event, set dedupe key
- Subsequent at same obs_point: Dedupe key exists → skip emission (silent, logged at DEBUG level)
- Different obs_point: Uses different dedupe key → emits new event
- After TTL: Dedupe key expires → plan can be re-observed at that obs_point

---

## Configuration

### Environment Variables

All configuration is via environment file: `/etc/quantum/apply.env`

```bash
# Enable P2.8A heat observation
P28_HEAT_OBS_ENABLED=true

# Output stream for observed events
P28_HEAT_OBS_STREAM=quantum:stream:apply.heat.observed

# HeatBridge lookup key prefix
P28_HEAT_LOOKUP_PREFIX=quantum:harvest:heat:by_plan:

# Deduplication TTL (seconds)
P28_DEDUPE_TTL_SEC=600

# Max debug JSON characters (prevents excessive stream sizes)
P28_MAX_DEBUG_CHARS=400
```

### Default Values (Hardcoded Fallbacks)

| Variable | Default | Description |
|----------|---------|-------------|
| P28_HEAT_OBS_ENABLED | true | Enable observer (false disables completely) |
| P28_HEAT_OBS_STREAM | quantum:stream:apply.heat.observed | Output stream name |
| P28_HEAT_LOOKUP_PREFIX | quantum:harvest:heat:by_plan: | HeatBridge key prefix |
| P28_DEDUPE_TTL_SEC | 600 | Dedupe window (10 min) |
| P28_MAX_DEBUG_CHARS | 400 | Max debug JSON size |

---

## Deployment

### Prerequisites

1. **Apply service** is running (quantum-apply.service)
2. **HeatBridge service** (P2.7) is running and populated with heat keys
3. **Redis** is accessible

### Step 1: Update Apply Environment

```bash
# Edit apply.env to enable P2.8A (if not already present)
sudo vi /etc/quantum/apply.env

# Add P2.8A config block:
P28_HEAT_OBS_ENABLED=true
P28_HEAT_OBS_STREAM=quantum:stream:apply.heat.observed
P28_HEAT_LOOKUP_PREFIX=quantum:harvest:heat:by_plan:
P28_DEDUPE_TTL_SEC=600
P28_MAX_DEBUG_CHARS=400
```

### Step 2: Deploy Updated Code

```bash
# Pull latest code
cd /home/qt/quantum_trader
git pull origin main

# Verify heat_observer.py exists
ls -lh microservices/apply_layer/heat_observer.py

# Verify main.py has observer import
grep "heat_observer" microservices/apply_layer/main.py
```

### Step 3: Restart Apply Service

```bash
# Restart to pick up new code + env vars
sudo systemctl restart quantum-apply

# Verify service started
sudo systemctl status quantum-apply

# Check logs for P2.8A initialization
sudo journalctl -u quantum-apply -n 20 --no-pager | grep "P2.8A"
```

### Step 4: Verify

```bash
# Check that observer is enabled in logs
sudo journalctl -u quantum-apply -n 50 --no-pager | grep -i "heat observer"

# Check observed stream exists (may take 1 apply cycle to appear)
redis-cli XLEN quantum:stream:apply.heat.observed

# View recent observed events
redis-cli XREVRANGE quantum:stream:apply.heat.observed + - COUNT 5
```

---

## Redis Commands for Debugging

### View Observed Events

```bash
# Get latest 10 observed events
redis-cli XREVRANGE quantum:stream:apply.heat.observed + - COUNT 10

# Get events for specific symbol
redis-cli XREVRANGE quantum:stream:apply.heat.observed + - | grep BTCUSDT | head -20

# Count total observed events
redis-cli XLEN quantum:stream:apply.heat.observed
```

### Inspect Specific Observation

```bash
# Get fields for a specific event
redis-cli XRANGE quantum:stream:apply.heat.observed <message_id> <message_id>

# Example:
redis-cli XRANGE quantum:stream:apply.heat.observed 1735689600000-0 1735689600000-0
```

### Check Heat Keys

```bash
# List all heat keys (by_plan)
redis-cli KEYS "quantum:harvest:heat:by_plan:*" | head -10

# Inspect specific heat key
redis-cli HGETALL quantum:harvest:heat:by_plan:a4f3b8c2d1e5f6a7

# Check if heat key exists for a plan
redis-cli EXISTS quantum:harvest:heat:by_plan:a4f3b8c2d1e5f6a7
```

### Check Deduplication

```bash
# List active dedupe keys (within 10 min window)
redis-cli KEYS "quantum:dedupe:p28:*"

# Check if specific plan is deduplicated
redis-cli GET quantum:dedupe:p28:a4f3b8c2d1e5f6a7

# Check TTL of dedupe key
redis-cli TTL quantum:dedupe:p28:a4f3b8c2d1e5f6a7
```

---

## Proof Scripts

Two helper scripts are provided for testing:

### 1. `proof_p28_inject_plan_apply.py`

Injects synthetic plans for testing. Supports two modes:

#### Mode A: Harvest Proposal Injection (Legacy)

Injects proposal + heat key, relying on Apply to process and create plan_id.

**Usage**:

```bash
# Inject plan with heat (default: BTCUSDT, warm, DOWNGRADE)
python3 scripts/proof_p28_inject_plan_apply.py

# Inject plan without heat (test heat_found=0)
python3 scripts/proof_p28_inject_plan_apply.py --no_heat --symbol ETHUSDT

# Custom parameters
python3 scripts/proof_p28_inject_plan_apply.py \
  --symbol BTCUSDT \
  --action FULL_CLOSE_PROPOSED \
  --kill_score 0.35 \
  --heat_level hot \
  --heat_action HOLD_CLOSE
```

#### Mode B: Direct Apply.Plan Injection (Deterministic - **Recommended**)

Injects directly into `quantum:stream:apply.plan` with known `plan_id` for deterministic testing.

**Usage**:

```bash
# Inject with heat_found=1 (deterministic)
python3 scripts/proof_p28_inject_plan_apply.py \
  --inject_apply_plan \
  --plan_id test_plan_001 \
  --symbol BTCUSDT \
  --heat_level hot

# Inject with heat_found=0 (no heat key)
python3 scripts/proof_p28_inject_plan_apply.py \
  --inject_apply_plan \
  --plan_id test_plan_002 \
  --symbol ETHUSDT \
  --heat_level none
```

**Why Deterministic Mode?**

- **Known plan_id**: No reliance on Apply's plan_id generation timing
- **Instant observation**: Triggers observer at apply.plan consumption point
- **Reliable testing**: Test scripts can search for exact plan_id in observed stream
- **Proof-grade**: Enables 100% reproducible proof test cases

### 2. `proof_p28_apply_heat_observed.sh`

Comprehensive proof suite with 4 test cases using **deterministic injection**.

**Usage**:

```bash
# Run all tests
bash scripts/proof_p28_apply_heat_observed.sh
```

**Test Cases** (P2.8A.1 Deterministic):
- **Test A**: Heat found → inject apply.plan + heat key with plan_id=test_plan_a, verify observed event with heat_found=1
- **Test B**: Deduplication → re-inject same plan_id, verify no duplicate observed event (dedupe key working)
- **Test C**: Heat missing → inject apply.plan without heat key (plan_id=test_plan_c), verify observed event with heat_found=0 and heat_reason=missing
- **Test D**: Stream integrity → verify observed stream has events

**Expected Output**:

```
====================================================================
P2.8A.1 Apply Heat Observer Proof (Deterministic)
====================================================================

[0] Preflight: Redis connectivity
✅ PASS: Redis available

[A] Test: Heat found → observed event with heat_found=1
   Injecting plan+heat to apply.plan stream (deterministic)...
   Waiting 8s for Apply to consume apply.plan...
✅ PASS: Heat key exists
✅ PASS: Observed event found with heat_found=1

[B] Test: Deduplication → re-inject same plan_id, no duplicate event
✅ PASS: Dedupe key exists
✅ PASS: No duplicate observed event (dedupe working)


[C] Test: Heat missing → observed event with heat_found=0
   Plan ID: b2c3d4e5f6a7b8c9
   Waiting 12s for Apply to process...
✅ PASS: Observed event found with heat_found=0 (correct)
✅ PASS: heat_reason=missing (correct)

[D] Verify observed stream has events
✅ PASS: Observed stream has 3 events

====================================================================
✅ SUMMARY: PASS (all tests passed)
====================================================================
```

---

## Operational Behavior

### Fail-Open Guarantees

P2.8A observer is designed to NEVER impact Apply processing:

1. **Missing heat key**: `heat_found=0`, `heat_reason=missing` → emit observed event, continue
2. **Redis read error**: `heat_found=0`, `heat_reason=redis_error` → emit observed event, continue
3. **Stream write error**: Log warning, continue (no crash)
4. **JSON parse error**: Use fallback values, continue
5. **Observer exception**: Caught at top level, logged, Apply continues

**Implementation**:
```python
# In apply_layer/main.py, create_apply_plan():
if self.p28_enabled and heat_observer:
    try:
        heat_observer.observe(...)
    except Exception as e:
        # Catch-all to protect Apply (fail-open)
        logger.warning(f"{symbol}: Heat observer error (ignored): {e}")
```

### Performance Impact

- **Latency**: ~5-10ms per plan (1 HGETALL + 1 XADD)
- **Memory**: ~500 bytes per observed event
- **CPU**: < 0.1% (negligible)
- **Network**: 2 Redis round-trips per plan

### Stream Management

- **Max Length**: 10000 events (MAXLEN ~ 10000)
- **Automatic Trimming**: Oldest events dropped when limit reached
- **Storage**: ~5 MB for 10000 events
- **Retention**: Depends on Apply frequency (typically days to weeks)

---

## Integration with Downstream Services

### Future Use Cases

Once P2.8A is validated in production, observed events can be used by:

1. **Analytics Pipeline**: Track heat gate effectiveness over time
2. **Monitoring Dashboards**: Real-time heat coverage metrics
3. **Alerting**: Detect when heat keys are missing for extended periods
4. **Audit Logs**: Compliance trail for heat gate decisions
5. **A/B Testing**: Compare heat vs. no-heat decision outcomes

### Example Query: Heat Coverage Rate

```bash
# Get last 100 observed events
EVENTS=$(redis-cli XREVRANGE quantum:stream:apply.heat.observed + - COUNT 100)

# Count heat_found=1 vs heat_found=0
FOUND=$(echo "$EVENTS" | grep -c "heat_found.*1")
MISSING=$(echo "$EVENTS" | grep -c "heat_found.*0")

# Calculate coverage
echo "Heat coverage: $FOUND / $(($FOUND + $MISSING))"
```

---

## Troubleshooting

### No Observed Events in Stream

**Symptoms**: `redis-cli XLEN quantum:stream:apply.heat.observed` returns 0

**Checklist**:
1. Verify Apply service is running: `systemctl status quantum-apply`
2. Check P28 is enabled: `journalctl -u quantum-apply -n 50 | grep "P2.8A Heat Observer"`
3. Check Apply is processing plans: `journalctl -u quantum-apply -n 30 | grep "Plan"`
4. Verify harvest proposals exist: `redis-cli KEYS "quantum:harvest:*:proposal"`

### Observer Errors in Logs

**Symptoms**: `journalctl -u quantum-apply | grep "Heat observer error"`

**Common Causes**:
- Redis connection issues (check REDIS_HOST/PORT)
- HeatBridge keys missing (check P2.7 service status)
- Malformed heat keys (inspect with HGETALL)

### Duplicate Observed Events

**Symptoms**: Multiple events for same plan_id in short time window

**Checklist**:
1. Check dedupe TTL: `redis-cli TTL quantum:dedupe:p28:<plan_id>`
2. Verify dedupe keys are being created: `redis-cli KEYS "quantum:dedupe:p28:*"`
3. Check Apply dedupe (separate from P28): Apply may reprocess if its own dedupe expired

### High Stream Size

**Symptoms**: `redis-cli XLEN quantum:stream:apply.heat.observed` > 50000

**Solution**: Stream auto-trims at 10000 events. If growing beyond, check:
- MAXLEN parameter in observer code (should be 10000)
- Redis version (old versions may not support MAXLEN ~)
- Manual trim: `redis-cli XTRIM quantum:stream:apply.heat.observed MAXLEN ~ 10000`

---

## Metrics (P2.8A.2)

**Status**: Implemented in P2.8A.2 (2026-01-28)

Prometheus metrics provide continuous observability into heat coverage without any execution impact (fail-open design).

### Available Metrics

#### 1. `p28_observed_total`

**Type**: Counter  
**Labels**:
- `obs_point` - Observation point (`create_apply_plan` | `reconcile_close_consume`)
- `heat_found` - Heat key presence (`0` = missing, `1` = found)

**Description**: Total observed events emitted, labeled by observation point and heat presence

**Example Values**:
```
p28_observed_total{obs_point="create_apply_plan",heat_found="0"} 142
p28_observed_total{obs_point="create_apply_plan",heat_found="1"} 58
p28_observed_total{obs_point="reconcile_close_consume",heat_found="0"} 3
p28_observed_total{obs_point="reconcile_close_consume",heat_found="1"} 1
```

#### 2. `p28_heat_reason_total`

**Type**: Counter  
**Labels**:
- `obs_point` - Observation point (`create_apply_plan` | `reconcile_close_consume`)
- `reason` - Heat lookup outcome (`ok` | `missing` | `redis_error` | `parse_error` | `stale`)

**Description**: Total heat lookup results by reason, useful for debugging HeatBridge integration

**Example Values**:
```
p28_heat_reason_total{obs_point="create_apply_plan",reason="ok"} 58
p28_heat_reason_total{obs_point="create_apply_plan",reason="missing"} 142
p28_heat_reason_total{obs_point="reconcile_close_consume",reason="ok"} 1
```

### Metrics Endpoint

Metrics are exposed via Apply's existing Prometheus HTTP server:

**Endpoint**: `http://<apply-host>:<APPLY_METRICS_PORT>/metrics`  
**Default Port**: 8043 (configurable via `APPLY_METRICS_PORT` env)

**Example**:
```bash
curl -s http://localhost:8043/metrics | grep p28_
```

### Grafana Queries

#### Heat Coverage per Observation Point

**Query**:
```promql
sum by (obs_point, heat_found) (rate(p28_observed_total[5m]))
```

**Description**: Rate of observed events per minute, split by observation point and heat presence

**Use Case**: Monitor heat coverage in real-time, detect HeatBridge cache misses

**Alert Example**:
```promql
# Alert if heat_found=1 drops to zero for >15 minutes (HeatBridge down)
sum(rate(p28_observed_total{heat_found="1"}[5m])) == 0
```

#### Heat Lookup Failure Rate

**Query**:
```promql
sum by (obs_point, reason) (rate(p28_heat_reason_total{reason!="ok"}[5m])) 
  / 
sum by (obs_point) (rate(p28_heat_reason_total[5m]))
```

**Description**: Percentage of failed heat lookups (redis_error, parse_error, etc.)

**Use Case**: Detect Redis connectivity issues or HeatBridge data corruption

**Alert Example**:
```promql
# Alert if error rate >5% for >10 minutes
sum(rate(p28_heat_reason_total{reason="redis_error"}[5m])) 
  / 
sum(rate(p28_heat_reason_total[5m])) > 0.05
```

#### Reconcile Stream Activity

**Query**:
```promql
rate(p28_observed_total{obs_point="reconcile_close_consume"}[5m])
```

**Description**: Events per minute from reconcile.close consumption

**Use Case**: Detect unexpected reconciliation activity or test traffic in production

### Fail-Open Design

Metrics increment is wrapped in try/except to ensure **zero execution impact**:

- Metrics unavailable (prometheus_client not installed) → silently disabled, no errors
- Metrics increment failure → logged at DEBUG level, Apply continues normally
- No blocking operations, no network calls (in-process counter increment)

**Code Example**:
```python
if METRICS_AVAILABLE:
    try:
        p28_observed.labels(
            obs_point=obs_point,
            heat_found=str(heat_found)
        ).inc()
    except Exception as e:
        logger.debug(f"P2.8A.2: metrics increment failed: {e}")
```

### Label Cardinality

**IMPORTANT**: Metrics use ONLY low-cardinality labels:
- ✅ `obs_point` - 2 values (create_apply_plan, reconcile_close_consume)
- ✅ `heat_found` - 2 values (0, 1)
- ✅ `reason` - 5 values (ok, missing, redis_error, parse_error, stale)

**NEVER ADDED**:
- ❌ `plan_id` - high cardinality (unique per plan)
- ❌ `symbol` - medium cardinality (multiple trading pairs)

This prevents Prometheus "cardinality explosion" that could impact performance.

---

## Version History

| Version | Date | Changes |
|---------|------|---------|
| 1.0.0 | 2026-01-28 | Initial release: shadow observer, fail-open, dedupe, proof scripts |
| 1.1.0 | 2026-01-28 | P2.8A.2: Production-grade per-obs_point deduplication, explicit obs_point field |
| 1.2.0 | 2026-01-28 | P2.8A.2: Prometheus metrics (p28_observed_total, p28_heat_reason_total) |

---

## Support

For issues or questions:

1. Check logs: `sudo journalctl -u quantum-apply -f`
2. Run proof: `bash scripts/proof_p28_apply_heat_observed.sh`
3. Verify Redis: `redis-cli PING`
4. Check config: `cat /etc/quantum/apply.env | grep P28`
5. Inspect observed stream: `redis-cli XREVRANGE quantum:stream:apply.heat.observed + - COUNT 10`
6. Check metrics: `curl -s http://localhost:8043/metrics | grep p28_`
