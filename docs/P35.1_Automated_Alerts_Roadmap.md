# P3.5.1 Automated Alerts - Implementation Roadmap

**Sprint:** P3.5.1  
**Estimated Time:** 30-45 minutes (coding + testing)  
**Priority:** MEDIUM (enhances P3.5, not critical)  
**Dependencies:** P3.5 operational (âœ… DONE)

---

## Overview

P3.5 provides **real-time analytics**. P3.5.1 adds **automated alerts** when gates explode (one reason dominates >40% of decisions).

**Use Case:**
- Operator doesn't need to run dashboard queries manually
- System automatically detects gate explosions
- Alert events published to Redis stream
- Downstream consumers (Governor UI, Discord bot, AI Engine) react automatically

---

## Feature Specification

### Input
- **Source:** P3.5 rolling snapshots (computed every 60s)
- **Trigger:** Top reason in 5m window exceeds threshold
- **Thresholds:**
  - 40% = MEDIUM alert
  - 60% = HIGH alert
  - 80% = CRITICAL alert

### Output
- **Stream:** `quantum:p35:alerts`
- **Event Schema:**
  ```json
  {
    "window": "5m",
    "reason": "p33_permit_denied",
    "score": 1234,
    "total": 2000,
    "share": 0.62,
    "timestamp": 1769929500,
    "severity": "HIGH",
    "alert_id": "p35_alert_1769929500_p33_permit_denied"
  }
  ```

### Deduplication
- **Rate Limit:** Max 1 alert per (reason, window) per 5 minutes
- **Implementation:** Track `last_alert_ts` per reason in memory
- **Reset:** On service restart (acceptable, alerts are transient)

---

## Implementation Plan

### Step 1: Update Service Code (20 min)

**File:** `microservices/decision_intelligence/main.py`

**Changes:**

1. Add alert state tracking:
```python
def __init__(self, ...):
    # ... existing code ...
    self.last_alert_ts = {}  # reason -> timestamp
    self.alert_cooldown = 300  # 5 minutes
```

2. Add alert check method:
```python
def _check_alerts(self):
    """Check for gate explosion and publish alerts."""
    try:
        # Get 5m decision counts
        counts = self.redis.hgetall("quantum:p35:decision:counts:5m")
        if not counts:
            return
        
        total = sum(int(v) for v in counts.values())
        if total < 100:  # Skip if too few decisions
            return
        
        # Get top reason
        top_reasons = self.redis.zrevrange(
            "quantum:p35:reason:top:5m", 
            0, 0, 
            withscores=True
        )
        
        if not top_reasons:
            return
        
        reason, score = top_reasons[0]
        share = score / total
        
        # Determine severity
        if share < 0.40:
            return  # Below threshold
        elif share < 0.60:
            severity = "MEDIUM"
        elif share < 0.80:
            severity = "HIGH"
        else:
            severity = "CRITICAL"
        
        # Check cooldown
        now = int(time.time())
        if reason in self.last_alert_ts:
            if now - self.last_alert_ts[reason] < self.alert_cooldown:
                return  # Still in cooldown
        
        # Publish alert
        alert_id = f"p35_alert_{now}_{reason}"
        alert_event = {
            "window": "5m",
            "reason": reason,
            "score": int(score),
            "total": total,
            "share": round(share, 3),
            "timestamp": now,
            "severity": severity,
            "alert_id": alert_id
        }
        
        self.redis.xadd("quantum:p35:alerts", alert_event, maxlen=1000)
        self.last_alert_ts[reason] = now
        
        logger.warning(
            f"ðŸš¨ ALERT ({severity}): {reason} @ {share*100:.1f}% "
            f"({int(score)}/{total})"
        )
        
    except Exception as e:
        logger.error(f"Alert check failed: {e}")
```

3. Call from main loop:
```python
async def run(self):
    # ... existing code ...
    
    # Add to snapshot computation section
    if time.time() - last_snapshot_ts >= 60:
        self._compute_snapshots()
        self._check_alerts()  # â† ADD THIS
        last_snapshot_ts = time.time()
```

### Step 2: Update Configuration (5 min)

**File:** `etc/quantum/p35-decision-intelligence.env`

**Add:**
```bash
# Alert thresholds
P35_ALERT_THRESHOLD_MEDIUM=0.40
P35_ALERT_THRESHOLD_HIGH=0.60
P35_ALERT_THRESHOLD_CRITICAL=0.80
P35_ALERT_COOLDOWN=300  # 5 minutes between alerts for same reason
```

**Update service to read:**
```python
def __init__(self, ...):
    # ... existing code ...
    self.alert_threshold_medium = float(os.getenv("P35_ALERT_THRESHOLD_MEDIUM", "0.40"))
    self.alert_threshold_high = float(os.getenv("P35_ALERT_THRESHOLD_HIGH", "0.60"))
    self.alert_threshold_critical = float(os.getenv("P35_ALERT_THRESHOLD_CRITICAL", "0.80"))
    self.alert_cooldown = int(os.getenv("P35_ALERT_COOLDOWN", "300"))
```

### Step 3: Create Alert Consumer Example (10 min)

**File:** `scripts/p35_alert_consumer_example.sh`

```bash
#!/bin/bash
# P3.5.1 Alert Consumer - Example for testing

echo "Listening for P3.5 alerts..."
echo "Press Ctrl+C to stop"
echo ""

redis-cli XREAD BLOCK 0 STREAMS quantum:p35:alerts $ | while read -r line; do
    if [[ "$line" == *"severity"* ]]; then
        echo "[$(date +%H:%M:%S)] ALERT: $line"
    fi
done
```

### Step 4: Testing (10 min)

**Test 1: Normal operation (no alerts)**
```bash
# Ensure no single gate dominates
bash scripts/p35_dashboard_queries.sh c
# Expected: No gate >40%
```

**Test 2: Simulate gate explosion**
```bash
# Option A: Wait for natural gate explosion (may take hours)
# Option B: Lower threshold temporarily for testing
redis-cli HSET quantum:p35:config alert_threshold_medium 0.10

# Run alert check cycle
systemctl restart quantum-p35-decision-intelligence

# Check for alerts
redis-cli XREVRANGE quantum:p35:alerts - + COUNT 10
```

**Test 3: Verify deduplication**
```bash
# Should see max 1 alert per reason per 5 minutes
redis-cli XREVRANGE quantum:p35:alerts - + COUNT 50 | grep reason
```

---

## Deployment Steps

1. **Pull latest code** (includes P3.5.1 changes)
2. **Update config** (add alert thresholds to env file)
3. **Restart service** (`systemctl restart quantum-p35-decision-intelligence`)
4. **Verify alerts stream created** (`redis-cli TYPE quantum:p35:alerts`)
5. **Monitor for first alert** (`redis-cli XREAD BLOCK 0 STREAMS quantum:p35:alerts $`)

---

## Integration Points

### Governor UI (Future)
```javascript
// Subscribe to alert stream
redis.xread('BLOCK', 0, 'STREAMS', 'quantum:p35:alerts', lastId, (alerts) => {
  alerts.forEach(alert => {
    showNotification({
      title: `Gate Explosion: ${alert.reason}`,
      message: `${alert.share*100}% of decisions blocked`,
      severity: alert.severity,
      action: 'View Details'
    });
  });
});
```

### Discord Bot (Future)
```python
# Forward HIGH/CRITICAL alerts to Discord
async def consume_alerts():
    while True:
        alerts = redis.xread({'quantum:p35:alerts': last_id}, block=0)
        for alert in alerts:
            if alert['severity'] in ['HIGH', 'CRITICAL']:
                await discord_channel.send(
                    f"ðŸš¨ **{alert['severity']}**: `{alert['reason']}` "
                    f"is blocking **{alert['share']*100:.1f}%** of trades"
                )
```

### AI Engine (Future)
```python
# Adjust strategy if insufficient_confidence dominates
async def consume_alerts():
    while True:
        alerts = redis.xread({'quantum:p35:alerts': last_id}, block=0)
        for alert in alerts:
            if alert['reason'] == 'insufficient_confidence':
                logger.warning("Confidence threshold may be too high")
                # Auto-adjust or notify for manual review
```

---

## Metrics & Monitoring

### Key Metrics
1. **Alert Rate:** Alerts per hour (target: <5/hour)
2. **Alert Severity Distribution:** MEDIUM/HIGH/CRITICAL breakdown
3. **Top Alerted Gates:** Which reasons trigger alerts most often
4. **Mean Time to Alert:** How fast do we detect gate explosions

### Queries
```bash
# Alert rate (last hour)
redis-cli XLEN quantum:p35:alerts

# Recent alerts
redis-cli XREVRANGE quantum:p35:alerts - + COUNT 20

# Alert distribution by severity
redis-cli XREVRANGE quantum:p35:alerts - + COUNT 100 | grep severity | sort | uniq -c

# Top alerted gates
redis-cli XREVRANGE quantum:p35:alerts - + COUNT 100 | grep reason | sort | uniq -c
```

---

## Rollback Plan

If P3.5.1 causes issues:

1. **Disable alert check:**
   ```bash
   # Comment out _check_alerts() call in main.py
   sed -i 's/self._check_alerts()/#self._check_alerts()/' \
     microservices/decision_intelligence/main.py
   systemctl restart quantum-p35-decision-intelligence
   ```

2. **Or: Set thresholds very high (effectively disable):**
   ```bash
   redis-cli HSET quantum:p35:config alert_threshold_medium 0.99
   systemctl restart quantum-p35-decision-intelligence
   ```

3. **Full rollback:**
   ```bash
   git revert <commit-hash>
   bash deploy_p35.sh
   ```

---

## Success Criteria

- âœ… Service remains stable (no crashes, no memory leaks)
- âœ… Alerts published when gate exceeds threshold
- âœ… Deduplication works (max 1 alert per reason per 5 min)
- âœ… No false positives (alerts only when truly anomalous)
- âœ… Alert stream TTL capped (maxlen=1000, ~24 hours of history)

---

## Future Enhancements (P3.5.2+)

1. **Alert Routing:** Different actions per severity
   - MEDIUM â†’ Log only
   - HIGH â†’ Discord notification
   - CRITICAL â†’ Page on-call engineer

2. **Alert Context:** Include recent bucket samples in alert
   - Last 5 minutes of decision distribution
   - Symbol breakdown (which symbols affected)

3. **Alert Trends:** Detect increasing share over time
   - If gate share growing 10%+ per hour â†’ early warning

4. **Alert Suppression:** Configurable quiet hours
   - Don't alert during expected low-volume periods

5. **Multi-Window Alerts:** Alert if gate persists across windows
   - Example: Gate >40% in 5m, 15m, AND 1h â†’ definitely stuck

---

## Cost-Benefit Analysis

**Cost:**
- 30-45 minutes implementation time
- +50 lines of code
- +10-20 KB/hour Redis memory (alert stream)
- Negligible CPU overhead (<0.1%)

**Benefit:**
- **Proactive detection** of gate explosions (vs. reactive dashboard checks)
- **Faster response** to trading blockages (alerts within 60s)
- **Automation foundation** for future self-healing systems
- **Operator relief** (system watches itself)

**ROI:** HIGH (quick win, significant operational improvement)

---

## Timeline

| Task | Duration | Status |
|------|----------|--------|
| Code implementation | 20 min | â³ PENDING |
| Config updates | 5 min | â³ PENDING |
| Testing | 10 min | â³ PENDING |
| Deployment | 5 min | â³ PENDING |
| Verification | 10 min | â³ PENDING |
| **TOTAL** | **50 min** | â³ PENDING |

---

## Approval & Next Steps

**Recommendation:** Implement P3.5.1 in next maintenance window (low risk, high value).

**Prerequisites:**
- âœ… P3.5 stable (verified: 14+ hours uptime, 16,300+ messages)
- âœ… Dashboard queries working (tested)
- âœ… Action mapping defined (documented)

**Decision:** HOLD for user approval (not urgent, nice-to-have).

---

**Document Version:** 1.0  
**Last Updated:** 2026-02-01  
**Author:** AI Assistant (Decision Intelligence Team)
