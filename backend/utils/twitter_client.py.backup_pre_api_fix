"""Minimal Twitter/X client wrapper.

Environment variables supported:
- X_BEARER_TOKEN: preferred (App-only bearer token for v2 endpoints)
- X_API_KEY, X_API_SECRET, X_ACCESS_TOKEN, X_ACCESS_SECRET: optional OAuth1

Resilience goals:
- If credentials missing: returns neutral sentiment (mock mode)
- If the legacy ``config.config`` import fails (e.g. path issues when running
    from a subdirectory) we fall back to ``from config import load_config``.
- As a last resort we provide a tiny shim returning an object with a
    ``x_bearer_token`` attribute so downstream code continues without crashes.
"""

from typing import Optional, Dict, Any
try:  # Primary import style used throughout the codebase
    from config.config import load_config  # type: ignore[import-not-found, import-untyped]
except ModuleNotFoundError:  # pragma: no cover - fallback when running in isolated cwd
    try:
        from config import load_config  # type: ignore[import-not-found, import-untyped]
    except ModuleNotFoundError:  # Final fallback: define a shim
        def load_config():  # type: ignore[return-type]
            class _Shim:  # minimal surface expected by caller
                x_bearer_token: Optional[str] = None
            return _Shim()
import time
import requests  # type: ignore[import-untyped]
import warnings

try:
    from backend.utils.telemetry import record_cache_hit, record_cache_miss, record_cache_write
except ModuleNotFoundError:  # pragma: no cover - fallback for package-relative imports
    from utils.telemetry import record_cache_hit, record_cache_miss, record_cache_write  # type: ignore

# Small in-process cache to avoid repeated API calls during short tests
_CACHE: Dict[str, Any] = {}


class TwitterClient:
    """Robust, minimal Twitter/X client for sentiment heuristics.

    Behavior and features:
    - Uses X_BEARER_TOKEN when available. Falls back to mock if not configured.
    - Retries transient errors (5xx, 429) with exponential backoff.
    - Simple in-memory TTL cache to limit repeated calls.
    - Small, explainable sentiment heuristic (word counting) to avoid heavy NLP deps.
    """

    def __init__(self):
        # load_config may come from one of several fallbacks; all expose
        # x_bearer_token (or None) to indicate mock mode.
        cfg = load_config()
        self.bearer = cfg.x_bearer_token
        # Optionally support OAuth1 env vars in the future
        self.mock = not bool(self.bearer)
        self.base_v2 = "https://api.twitter.com/2"

    def _cached(self, key: str, ttl: int = 30) -> Optional[Any]:
        e = _CACHE.get(key)
        if not e:
            record_cache_miss("twitter_recent_search")
            return None
        ts, val = e
        if time.time() - ts > ttl:
            del _CACHE[key]
            record_cache_miss("twitter_recent_search")
            return None
        record_cache_hit("twitter_recent_search")
        return val

    def _set_cache(self, key: str, val: Any) -> None:
        _CACHE[key] = (time.time(), val)
        record_cache_write("twitter_recent_search")

    def _request_with_retries(
        self,
        url: str,
        params: dict,
        headers: dict,
        max_attempts: int = 3,
        timeout: int = 6,
    ) -> Optional[Any]:
        attempt = 0
        while attempt < max_attempts:
            try:
                r = requests.get(url, params=params, headers=headers, timeout=timeout)
                if r.status_code == 200:
                    return r
                # If rate limited or server error, back off and retry
                if r.status_code in (429, 500, 502, 503, 504):
                    backoff = (2**attempt) + (0.1 * attempt)
                    time.sleep(backoff)
                    attempt += 1
                    continue
                # other client errors: return response for caller to inspect
                return r
            except requests.RequestException:
                # network blip: backoff and retry
                backoff = (2**attempt) + 0.1
                time.sleep(backoff)
                attempt += 1
                continue
        return None

    def sentiment_for_symbol(
        self, symbol: Optional[str] = None, max_results: int = 20
    ) -> Dict[str, Any]:
        """Return a lightweight sentiment summary for a symbol.

        Args:
            symbol: e.g. 'BTC' or 'ETH'. If None, a general crypto query is used.
            max_results: how many recent tweets to fetch (bounded by API limits).

        Returns:
            dict with keys: score (float), label (str), source (twitter|mock|error),
            and optional code.
        """
        if self.mock:
            return {"score": 0.0, "label": "neutral", "source": "mock"}

        q = (symbol or "crypto") + " -is:retweet lang:en"
        cache_key = f"tw:{q}:{max_results}"
        cached = self._cached(cache_key, ttl=30)
        if cached:
            return cached

        headers = {"Authorization": f"Bearer {self.bearer}"}
        # Twitter v2 recent search allows max_results up to 100 depending on access tier
        params = {
            "query": q,
            "max_results": min(100, max_results),
            "tweet.fields": "text,created_at",
        }
        url = f"{self.base_v2}/tweets/search/recent"

        r = self._request_with_retries(
            url, params=params, headers=headers, max_attempts=4, timeout=8
        )
        if r is None:
            warnings.warn("Twitter API request failed after retries")
            return {"score": 0.0, "label": "neutral", "source": "error"}

        if r.status_code != 200:
            return {
                "score": 0.0,
                "label": "neutral",
                "source": "error",
                "code": r.status_code,
            }

        data = r.json()
        texts = [t.get("text", "") for t in data.get("data", [])]

        # trivial, deterministic heuristic: count positive/negative tokens
        pos_words = ["good", "great", "bull", "moon", "buy", "bullish", "gain", "pump"]
        neg_words = ["bad", "sell", "bear", "down", "dump", "loss", "crash"]
        score: float = 0.0
        for txt in texts:
            low = txt.lower()
            for w in pos_words:
                if w in low:
                    score += 1.0
            for w in neg_words:
                if w in low:
                    score -= 1.0

        # normalize to range roughly between -1.0 and 1.0
        if texts:
            denom = float(max(1, len(texts) * 2))
            score = score / denom
            # clamp
            score = max(-1.0, min(1.0, score))
        else:
            score = 0.0

        out = {
            "score": float(score),
            "label": (
                "positive" if score > 0 else "negative" if score < 0 else "neutral"
            ),
            "source": "twitter",
        }
        self._set_cache(cache_key, out)
        return out

    def global_sentiment(self) -> Dict[str, Any]:
        return self.sentiment_for_symbol(None)
