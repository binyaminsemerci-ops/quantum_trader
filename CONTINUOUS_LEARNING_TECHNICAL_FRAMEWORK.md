# CONTINUOUS LEARNING: TECHNICAL FRAMEWORK

**Module 6: Continuous Learning - Section 2**

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CONTINUOUS LEARNING SYSTEM                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚               â”‚               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
        â”‚ Performance  â”‚ â”‚  Feature  â”‚ â”‚   Model     â”‚
        â”‚  Monitor     â”‚ â”‚  Tracker  â”‚ â”‚ Versioning  â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
               â”‚               â”‚               â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Retraining Engine  â”‚
                    â”‚  - Trigger Logic    â”‚
                    â”‚  - Data Collection  â”‚
                    â”‚  - Model Training   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚              â”‚              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
        â”‚   Online     â”‚ â”‚ Shadow  â”‚ â”‚   Archive   â”‚
        â”‚  Learning    â”‚ â”‚ Testing â”‚ â”‚  Manager    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1. PERFORMANCE MONITORING

### 1.1 Exponentially Weighted Moving Average (EWMA)

Track model performance decay using EWMA:

**Formula:**
```
EWMA(t) = Î± Ã— Performance(t) + (1 - Î±) Ã— EWMA(t-1)
```

**Where:**
- Î± = smoothing factor (0.1 recommended)
- Performance(t) = current metric (WR, Sharpe, PnL)
- EWMA(t-1) = previous EWMA value

**Decay Detection:**
```
Decay = Baseline_WR - EWMA_WR

Trigger Retraining if:
  Decay > threshold (3pp for WR)
```

**Example:**
```python
# Baseline (promotion): 58% WR
# Week 1: 57% â†’ EWMA = 0.1Ã—57 + 0.9Ã—58 = 57.9%
# Week 2: 56% â†’ EWMA = 0.1Ã—56 + 0.9Ã—57.9 = 57.71%
# Week 3: 54% â†’ EWMA = 0.1Ã—54 + 0.9Ã—57.71 = 57.34%
# Week 4: 53% â†’ EWMA = 0.1Ã—53 + 0.9Ã—57.34 = 56.91%

# Decay = 58% - 56.91% = 1.09pp (no trigger yet)

# Week 5: 52% â†’ EWMA = 0.1Ã—52 + 0.9Ã—56.91 = 56.42%
# Decay = 58% - 56.42% = 1.58pp (no trigger)

# Week 6: 50% â†’ EWMA = 0.1Ã—50 + 0.9Ã—56.42 = 55.78%
# Decay = 58% - 55.78% = 2.22pp (no trigger)

# Week 7: 49% â†’ EWMA = 0.1Ã—49 + 0.9Ã—55.78 = 55.10%
# Decay = 58% - 55.10% = 2.90pp (no trigger)

# Week 8: 48% â†’ EWMA = 0.1Ã—48 + 0.9Ã—55.10 = 54.39%
# Decay = 58% - 54.39% = 3.61pp ðŸ”¥ TRIGGER RETRAINING!
```

**Advantages:**
- Robust to short-term variance
- Smooths out lucky/unlucky streaks
- Clear decay threshold

---

### 1.2 CUSUM (Cumulative Sum Control Chart)

Detect sudden performance shifts faster than EWMA:

**Formula:**
```
CUSUMâº(t) = max(0, CUSUMâº(t-1) + x(t) - k)
CUSUMâ»(t) = max(0, CUSUMâ»(t-1) - x(t) - k)
```

**Where:**
- x(t) = current performance - baseline
- k = slack parameter (0.5 recommended)
- CUSUMâº = upward shift detector
- CUSUMâ» = downward shift detector

**Trigger:**
```
if CUSUMâ»(t) > h:  # h = threshold (5.0 recommended)
    trigger_retraining()
```

**Example:**
```python
# Baseline: 58% WR, k=0.5, h=5.0

# Trade results: [Win, Win, Loss, Loss, Loss, Loss, Loss]
# Observed WR: 58%, 58%, 54%, 52%, 50%, 48%, 46%

# x(t) = observed - baseline
# Trade 1: x=0, CUSUMâ» = 0
# Trade 2: x=0, CUSUMâ» = 0
# Trade 3: x=-4, CUSUMâ» = max(0, 0-(-4)-0.5) = 3.5
# Trade 4: x=-6, CUSUMâ» = max(0, 3.5-(-6)-0.5) = 9.0 > 5.0 ðŸ”¥ TRIGGER!

# CUSUM detected shift in 4 trades
# EWMA would need 8-10 trades
```

**Advantages:**
- Faster detection (50-70% faster than EWMA)
- Detects sudden shifts
- Complements EWMA (use both)

---

### 1.3 Statistical Process Control (SPC)

Monitor multiple metrics simultaneously:

**Control Limits:**
```
UCL = Î¼ + 3Ïƒ  # Upper Control Limit
LCL = Î¼ - 3Ïƒ  # Lower Control Limit
```

**Where:**
- Î¼ = baseline metric mean
- Ïƒ = baseline metric standard deviation

**Out-of-Control Rules:**
- 1 point beyond 3Ïƒ (UCL/LCL)
- 2 of 3 consecutive points beyond 2Ïƒ
- 4 of 5 consecutive points beyond 1Ïƒ
- 8 consecutive points on one side of center

**Example:**
```python
# Win Rate Control Chart
Î¼ = 58%, Ïƒ = 3%
UCL = 58% + 3Ã—3% = 67%
LCL = 58% - 3Ã—3% = 49%

# Recent 10 trades WR: 54%, 52%, 50%, 48%, 47%, 45%, 44%, 43%, 42%, 41%

# Trade 8: 43% < 49% (LCL) ðŸ”¥ OUT OF CONTROL!
# Action: Trigger retraining

# Sharpe Ratio Control Chart
Î¼ = 1.85, Ïƒ = 0.25
UCL = 1.85 + 3Ã—0.25 = 2.60
LCL = 1.85 - 3Ã—0.25 = 1.10

# Recent Sharpe: 1.80, 1.75, 1.60, 1.50, 1.40, 1.30, 1.20, 1.05 < LCL ðŸ”¥
```

---

## 2. FEATURE IMPORTANCE TRACKING

### 2.1 SHAP (SHapley Additive exPlanations)

Measure each feature's contribution to model predictions:

**Formula:**
```
Ï†áµ¢(f) = Î£ [|S|!Â·(|N|-|S|-1)! / |N|!] Â· [f(Sâˆª{i}) - f(S)]
      SâŠ†N\{i}
```

**Where:**
- Ï†áµ¢(f) = SHAP value for feature i
- N = set of all features
- S = subset of features
- f(S) = model prediction with features S

**Interpretation:**
- Ï†áµ¢ > 0: Feature increases prediction
- Ï†áµ¢ < 0: Feature decreases prediction
- |Ï†áµ¢| = feature importance

**Example:**
```python
# XGBoost prediction for BTCUSDT LONG

Features:
  - RSI: 65 â†’ Ï†_RSI = +0.05 (bullish)
  - MACD: -0.02 â†’ Ï†_MACD = -0.03 (bearish)
  - Volume: 1.2M â†’ Ï†_Volume = +0.08 (bullish)
  - OB_Imbalance: 0.15 â†’ Ï†_OB = +0.12 (bullish)

Prediction = base_value + Î£Ï†áµ¢
           = 0.50 + (0.05 - 0.03 + 0.08 + 0.12)
           = 0.50 + 0.22
           = 0.72 (72% confidence LONG)

Feature Ranking by |Ï†áµ¢|:
  1. Order Book Imbalance: 0.12
  2. Volume: 0.08
  3. RSI: 0.05
  4. MACD: 0.03
```

---

### 2.2 Feature Drift Detection

Monitor feature importance changes over time:

**Jensen-Shannon Divergence:**
```
D_JS(P || Q) = 0.5 Â· D_KL(P || M) + 0.5 Â· D_KL(Q || M)

where M = 0.5 Â· (P + Q)
```

**Where:**
- P = baseline feature importance distribution
- Q = current feature importance distribution
- D_KL = Kullback-Leibler divergence

**Trigger:**
```
if D_JS > 0.3:
    # Significant feature shift
    trigger_retraining()
```

**Example:**
```python
# Month 1 (Baseline):
P = {
    'RSI': 0.30,
    'MACD': 0.25,
    'Volume': 0.20,
    'ATR': 0.15,
    'OB': 0.10
}

# Month 3 (Current):
Q = {
    'RSI': 0.15,      # Dropped 50%
    'MACD': 0.10,     # Dropped 60%
    'Volume': 0.15,   # Dropped 25%
    'ATR': 0.10,      # Dropped 33%
    'OB': 0.50        # Up 5x! ðŸ”¥
}

# Calculate D_JS:
M = {
    'RSI': 0.225,
    'MACD': 0.175,
    'Volume': 0.175,
    'ATR': 0.125,
    'OB': 0.30
}

D_KL(P || M) = Î£ P(i) Â· log(P(i) / M(i))
D_KL(Q || M) = Î£ Q(i) Â· log(Q(i) / M(i))

D_JS â‰ˆ 0.42 > 0.3 ðŸ”¥ FEATURE DRIFT DETECTED!
Action: Retrain with emphasis on Order Book features
```

---

### 2.3 Incremental Feature Importance

Update feature importance without full recomputation:

**Exponential Moving Average Update:**
```
Importance_new(i) = Î± Â· Importance_current(i) + (1-Î±) Â· Importance_old(i)
```

**Where:**
- Î± = learning rate (0.01 - 0.05)
- Importance_current(i) = SHAP value from latest trade
- Importance_old(i) = previous average importance

**Example:**
```python
# Feature: RSI
# Previous avg importance: 0.30

# Trade 1: SHAP_RSI = 0.05
# Importance_new = 0.05 Ã— 0.05 + 0.95 Ã— 0.30 = 0.2875

# Trade 2: SHAP_RSI = 0.08
# Importance_new = 0.05 Ã— 0.08 + 0.95 Ã— 0.2875 = 0.2771

# Trade 100: Average â‰ˆ 0.15 (dropped from 0.30)
# Feature RSI losing importance over time
```

---

## 3. AUTOMATED RETRAINING

### 3.1 Retraining Trigger Logic

**Multi-Criterion Trigger:**
```
Trigger Retraining if ANY:
  1. EWMA decay > 3pp (WR)
  2. CUSUMâ» > 5.0
  3. SPC out-of-control (8+ consecutive below center)
  4. Feature drift D_JS > 0.3
  5. Scheduled monthly retrain
  6. Manual trigger
```

**Combined Score:**
```
Urgency Score = w1Â·EWMA_decay + w2Â·CUSUM + w3Â·SPC_violations + w4Â·D_JS

Thresholds:
  Score > 10: ðŸ”¥ CRITICAL (retrain immediately)
  Score > 5:  âš ï¸  WARNING (retrain within 24h)
  Score > 2:  â„¹ï¸  NOTICE (schedule retrain)
  Score â‰¤ 2:  âœ… HEALTHY (no action)
```

**Example:**
```python
# Week 8 Metrics:
EWMA_decay = 3.61pp  â†’ w1 = 3.0, contribution = 10.83
CUSUMâ» = 4.2        â†’ w2 = 1.0, contribution = 4.2
SPC_violations = 2  â†’ w3 = 0.5, contribution = 1.0
D_JS = 0.25         â†’ w4 = 10, contribution = 2.5

Urgency Score = 10.83 + 4.2 + 1.0 + 2.5 = 18.53 > 10 ðŸ”¥ CRITICAL!

Action: Trigger retraining IMMEDIATELY
```

---

### 3.2 Training Data Window Selection

**Sliding Window Approach:**
```
Data = [Trade_(t-n), Trade_(t-n+1), ..., Trade_(t-1), Trade_t]
```

**Where:**
- n = window size (10,000 trades recommended)
- t = current time

**Window Size Selection:**
```
Optimal Window = arg max E[Performance(model_trained_on_window)]
                   n

Trade-off:
  Small n (1,000):  Fast, adapts quickly, high variance
  Medium n (10,000): Balanced (recommended)
  Large n (50,000):  Slow, stable, may include stale data
```

**Example:**
```python
# Current: November 2025, 15,000 trades total

# Window 1 (Last 10K): October-November data
# Contains: Post-halving volatility, current market regime
# Performance: 61% WR

# Window 2 (Last 5K): November only
# Contains: Very recent data, high variance
# Performance: 59% WR (less stable)

# Window 3 (All 15K): August-November
# Contains: Pre-halving + post-halving mixed
# Performance: 57% WR (stale patterns)

# Optimal: Window 1 (10K trades) âœ…
```

---

### 3.3 Retraining Algorithm

**Procedure:**
```
1. Fetch Data:
   - Last 10,000 trades
   - Features: Technical indicators + order book + sentiment
   - Labels: Win/Loss + PnL

2. Feature Engineering:
   - Update feature importance weights
   - Add new features (if drift detected)
   - Remove obsolete features (importance < 5%)

3. Train Model:
   - XGBoost with updated hyperparameters
   - 5-fold cross-validation
   - Early stopping (patience=50)

4. Evaluate:
   - Holdout test set (20% of data)
   - Metrics: WR, Sharpe, Sortino, MDD, Calmar

5. Version Control:
   - Save as model_v{version}
   - Metadata: timestamp, metrics, features used

6. Shadow Test:
   - Deploy as challenger (Module 5)
   - Test 500 trades (0% allocation)
   - Compare to champion

7. Promote (if better):
   - Statistical tests passed
   - Shadow test WR > champion WR
   - Promotion score â‰¥ 70/100
```

**Hyperparameter Optimization:**
```
# XGBoost Hyperparameters (auto-tuned)

# Learning rate decay:
lr(epoch) = lr_initial Ã— decay_factor^(epoch / decay_steps)

# Optimal range (Bayesian optimization):
params = {
    'learning_rate': [0.01, 0.1],
    'max_depth': [3, 10],
    'n_estimators': [100, 1000],
    'subsample': [0.6, 1.0],
    'colsample_bytree': [0.6, 1.0],
    'min_child_weight': [1, 10],
    'gamma': [0, 5]
}

# Objective: Maximize Sharpe Ratio (not just accuracy)
```

---

## 4. ONLINE LEARNING

### 4.1 Stochastic Gradient Descent (SGD) Update

Update model weights with each new trade:

**Formula:**
```
Î¸_{t+1} = Î¸_t - Î· Â· âˆ‡L(Î¸_t, x_t, y_t)
```

**Where:**
- Î¸_t = model weights at time t
- Î· = learning rate (0.001 - 0.01)
- âˆ‡L = gradient of loss function
- x_t = features from trade t
- y_t = outcome (win/loss)

**Loss Function (Binary Cross-Entropy):**
```
L(Î¸, x, y) = -[yÂ·log(Å·) + (1-y)Â·log(1-Å·)]

where Å· = Ïƒ(Î¸áµ€x) = 1 / (1 + e^(-Î¸áµ€x))
```

**Example:**
```python
# Current weights: Î¸ = [0.5, 0.3, 0.2, 0.1]
# Trade features: x = [65, -0.02, 1.2M, 0.15] (RSI, MACD, Vol, OB)
# Prediction: Å· = Ïƒ(Î¸áµ€x) = 0.72 (72% confidence LONG)
# Actual: y = 1 (WIN)

# Compute gradient:
âˆ‡L = (Å· - y) Â· x
   = (0.72 - 1.0) Â· [65, -0.02, 1.2, 0.15]
   = -0.28 Â· [65, -0.02, 1.2, 0.15]
   = [-18.2, 0.0056, -0.336, -0.042]

# Update weights:
Î¸_new = Î¸ - 0.01 Â· âˆ‡L
      = [0.5, 0.3, 0.2, 0.1] - 0.01 Â· [-18.2, 0.0056, -0.336, -0.042]
      = [0.682, 0.2999, 0.2034, 0.1004]

# RSI weight increased (good predictor in this case)
```

---

### 4.2 Momentum-Based Online Learning

Add momentum to SGD for faster convergence:

**Formula:**
```
v_{t+1} = Î² Â· v_t + (1-Î²) Â· âˆ‡L(Î¸_t, x_t, y_t)
Î¸_{t+1} = Î¸_t - Î· Â· v_{t+1}
```

**Where:**
- v_t = velocity (momentum term)
- Î² = momentum coefficient (0.9 recommended)

**Advantages:**
- Faster convergence
- Smooths out noisy gradients
- Escapes local minima

**Example:**
```python
# Trade 1:
âˆ‡L_1 = [-18.2, 0.0056, -0.336, -0.042]
v_1 = 0.9 Ã— [0, 0, 0, 0] + 0.1 Ã— âˆ‡L_1 = [-1.82, 0.00056, -0.0336, -0.0042]
Î¸_1 = Î¸_0 - 0.01 Ã— v_1 = [0.5182, 0.29999, 0.20034, 0.10004]

# Trade 2:
âˆ‡L_2 = [-15.0, 0.002, -0.28, -0.035]
v_2 = 0.9 Ã— v_1 + 0.1 Ã— âˆ‡L_2 = [-3.138, 0.00070, -0.0582, -0.00728]
Î¸_2 = Î¸_1 - 0.01 Ã— v_2 = [0.54958, 0.29999, 0.20092, 0.10011]

# Momentum accelerates learning in consistent direction (RSI)
```

---

### 4.3 Adaptive Learning Rate (Adam)

Adjust learning rate per parameter:

**Formula:**
```
m_t = Î²1 Â· m_{t-1} + (1-Î²1) Â· âˆ‡L
v_t = Î²2 Â· v_{t-1} + (1-Î²2) Â· (âˆ‡L)Â²

mÌ‚_t = m_t / (1 - Î²1^t)
vÌ‚_t = v_t / (1 - Î²2^t)

Î¸_{t+1} = Î¸_t - Î· Â· mÌ‚_t / (âˆšvÌ‚_t + Îµ)
```

**Where:**
- m_t = first moment (mean)
- v_t = second moment (variance)
- Î²1 = 0.9, Î²2 = 0.999 (recommended)
- Îµ = 10^-8 (numerical stability)

**Advantages:**
- Parameter-specific learning rates
- Works well with sparse gradients
- Converges faster than SGD

---

### 4.4 Online Learning Safety

**Constraints:**
```
1. Maximum Weight Change per Update:
   |Î¸_new - Î¸_old| < max_delta (0.1 recommended)

2. Regularization:
   L_total = L_prediction + Î» Â· ||Î¸||Â²
   
   where Î» = 0.01 (L2 regularization)

3. Validation Check:
   if Performance_after_update < Performance_before - threshold:
       rollback_weights()

4. Update Frequency:
   Update every N trades (10-100 recommended)
   Not every single trade (too noisy)
```

---

## 5. MODEL VERSIONING

### 5.1 Version Control Schema

**Git-like versioning:**
```
model_v1.0.0  â†’ Initial deployment
model_v1.1.0  â†’ First retrain (minor update)
model_v1.1.1  â†’ Online learning checkpoint
model_v1.2.0  â†’ Second retrain (feature drift fix)
model_v2.0.0  â†’ Major architecture change
```

**Semantic Versioning:**
```
MAJOR.MINOR.PATCH

MAJOR: Breaking changes (new architecture)
MINOR: Retrain with new data
PATCH: Online learning updates
```

---

### 5.2 Model Metadata

**Stored with each version:**
```json
{
  "version": "1.2.3",
  "timestamp": "2025-11-26T04:00:00Z",
  "training_data": {
    "start_date": "2025-10-01",
    "end_date": "2025-11-25",
    "n_trades": 10000,
    "symbols": ["BTCUSDT", "ETHUSDT", ...]
  },
  "metrics": {
    "train": {"wr": 0.62, "sharpe": 2.1},
    "test": {"wr": 0.59, "sharpe": 1.95},
    "production": {"wr": 0.58, "sharpe": 1.85}
  },
  "features": {
    "RSI": 0.15,
    "MACD": 0.10,
    "Volume": 0.15,
    "OrderBook": 0.50,
    "ATR": 0.10
  },
  "hyperparameters": {
    "learning_rate": 0.05,
    "max_depth": 6,
    "n_estimators": 500
  },
  "parent_version": "1.2.2",
  "retrain_reason": "Feature drift (D_JS=0.42)"
}
```

---

### 5.3 Rollback Strategy

**Three-level rollback:**
```
Level 1: Instant Rollback (<30s)
  - Keep champion always in memory
  - Archive last 3 versions
  - Swap pointer instantly

Level 2: Recent Rollback (1-5 min)
  - Load from disk
  - Last 10 versions stored
  - Verify checksum

Level 3: Historical Rollback (5-15 min)
  - Load from S3/archive
  - All versions since v1.0
  - Rebuild if needed
```

---

## 6. PERFORMANCE BENCHMARKS

### Target Latencies:
- Performance monitoring: <10ms per trade
- SHAP computation: <50ms per prediction
- Online update: <100ms per trade
- Retraining: 30-60 minutes (full retrain)
- Shadow testing: 2-3 days (500 trades)
- Model deployment: <30 seconds

### Resource Requirements:
- Memory: 2-4 GB (model + data)
- CPU: 4 cores (online learning)
- GPU: 1x for retraining (optional)
- Storage: 50-100 GB (model versions + data)

---

## 7. INTEGRATION WITH PREVIOUS MODULES

### Module 1: Memory States
```python
# Retraining includes all memory states
data = fetch_trades(n=10000, include_memory_states=True)

# Online learning updates state-action values
if state == 'volatile_bullish':
    update_weights(state_features, outcome)
```

### Module 2: Reinforcement Signals
```python
# Feature importance tracks reward signals
feature_importance['reward_sharpe'] = 0.25
feature_importance['reward_win_rate'] = 0.20

# Retraining optimizes for reward function
loss = -reward_function(predictions, outcomes)
```

### Module 3: Drift Detection
```python
# Drift detector triggers retraining
if drift_detector.check_drift():
    retraining_engine.trigger(reason='drift_detected')
```

### Module 4: Covariate Shift
```python
# Feature drift detection = covariate shift detection
D_JS_features = compute_js_divergence(P_old, P_new)
if D_JS_features > 0.3:
    retrain(emphasize_new_covariates=True)
```

### Module 5: Shadow Models
```python
# Every retrained model = new challenger
new_model = retrain(data)
shadow_manager.register_model(
    model=new_model,
    role=ModelRole.CHALLENGER
)

# Promote only if proven better
if shadow_test_passed(new_model):
    shadow_manager.promote_challenger(new_model.name)
```

---

**Module 6 Section 2: Technical Framework - COMPLETE âœ…**

Next: Implementation (Python code)
