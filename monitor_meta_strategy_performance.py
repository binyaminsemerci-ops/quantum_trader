"""
Meta-Strategy Q-Learning Performance Monitor

Monitors Q-learning performance and provides recommendations for parameter tuning.
Run this script weekly to track learning progress and adjust epsilon/alpha.
"""
import asyncio
import json
import os
from pathlib import Path
from datetime import datetime, timezone
from typing import Dict, List
import sys

# Fix Windows console encoding for emoji support
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')

# Add backend to path
sys.path.insert(0, str(Path(__file__).parent / "backend"))

from backend.services.meta_strategy_integration import get_meta_strategy_integration


def print_header(title: str):
    """Print a formatted header"""
    print("\n" + "=" * 80)
    print(f"  {title}")
    print("=" * 80 + "\n")


def print_section(title: str):
    """Print a formatted section header"""
    print(f"\n{'â”€' * 80}")
    print(f"  {title}")
    print(f"{'â”€' * 80}\n")


def analyze_exploration_rate(metrics: Dict) -> str:
    """Analyze exploration rate and provide recommendations"""
    total_decisions = metrics.get("total_selections", 0)
    if total_decisions == 0:
        return "âŒ No decisions made yet - system needs more time"
    
    # Calculate exploration rate from Q-table
    integration = get_meta_strategy_integration()
    q_table = integration.meta_selector.q_table
    
    if not q_table:
        return "âŒ Q-table empty - system in cold start phase"
    
    # Count decisions per strategy
    strategy_counts = {}
    for key, stats in q_table.items():
        symbol, regime, strategy = key
        count = stats.count
        if strategy not in strategy_counts:
            strategy_counts[strategy] = 0
        strategy_counts[strategy] += count
    
    total_updates = sum(strategy_counts.values())
    if total_updates < 20:
        return "âš ï¸  Too few updates (<20) - continue with current epsilon (10%)"
    
    # Check if strategies are converging
    max_count = max(strategy_counts.values())
    min_count = min(strategy_counts.values())
    convergence_ratio = min_count / max_count if max_count > 0 else 0
    
    if convergence_ratio < 0.3:
        return "âœ… Good convergence - strategies emerging. Consider reducing epsilon to 0.05"
    else:
        return "âš ï¸  High convergence ratio - may need more exploration. Keep epsilon at 0.10"


def analyze_learning_stability(q_table: Dict) -> str:
    """Analyze EMA stability and provide alpha recommendations"""
    if not q_table:
        return "âŒ No Q-table data"
    
    # Calculate variance in EMA rewards
    ema_rewards = [stats.ema_reward for stats in q_table.values() if stats.count >= 3]
    
    if len(ema_rewards) < 5:
        return "âš ï¸  Too few samples (<5) - keep alpha at 0.20"
    
    import statistics
    mean_reward = statistics.mean(ema_rewards)
    stdev_reward = statistics.stdev(ema_rewards) if len(ema_rewards) > 1 else 0
    
    cv = stdev_reward / abs(mean_reward) if mean_reward != 0 else float('inf')
    
    if cv < 0.3:
        return "âœ… Stable learning - alpha=0.20 working well"
    elif cv < 0.5:
        return "âš ï¸  Moderate volatility - consider lowering alpha to 0.15"
    else:
        return "âŒ High volatility - lower alpha to 0.10 for more stability"


def get_regime_distribution(q_table: Dict) -> Dict[str, int]:
    """Get distribution of decisions per regime"""
    regime_counts = {}
    for key, stats in q_table.items():
        symbol, regime, strategy = key
        if regime not in regime_counts:
            regime_counts[regime] = 0
        regime_counts[regime] += stats.count
    return regime_counts


def get_strategy_distribution(q_table: Dict) -> Dict[str, int]:
    """Get distribution of decisions per strategy"""
    strategy_counts = {}
    for key, stats in q_table.items():
        symbol, regime, strategy = key
        if strategy not in strategy_counts:
            strategy_counts[strategy] = 0
        strategy_counts[strategy] += stats.count
    return strategy_counts


async def main():
    """Main monitoring function"""
    print_header("ğŸ“Š META-STRATEGY Q-LEARNING PERFORMANCE MONITOR")
    
    # Load Meta-Strategy Integration
    try:
        integration = get_meta_strategy_integration()
    except Exception as e:
        print(f"âŒ Error loading Meta-Strategy Integration: {e}")
        return
    
    # Get metrics
    metrics = integration.get_metrics()
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # SECTION 1: SYSTEM STATUS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print_section("1. System Status")
    
    print(f"Enabled: {'âœ… YES' if metrics['enabled'] else 'âŒ NO'}")
    print(f"Epsilon (Exploration Rate): {metrics['epsilon']:.0%}")
    print(f"Alpha (EMA Smoothing): {metrics['alpha']:.0%}")
    print(f"\nTotal Selections: {metrics['total_selections']}")
    print(f"Total Reward Updates: {metrics['total_reward_updates']}")
    print(f"Active Strategies: {metrics['active_strategies']}")
    
    if metrics['total_selections'] == 0:
        print("\nâš ï¸  No trading activity yet - system waiting for signals")
        return
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # SECTION 2: Q-TABLE ANALYSIS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print_section("2. Q-Table Analysis")
    
    q_table = integration.meta_selector.q_table
    print(f"Q-Table Entries: {len(q_table)}")
    
    if len(q_table) == 0:
        print("âŒ Q-table empty - no learning has occurred yet")
        print("   Wait for at least 5-10 trades to complete")
        return
    
    # Regime distribution
    regime_dist = get_regime_distribution(q_table)
    print(f"\nğŸ“ Regime Distribution:")
    for regime, count in sorted(regime_dist.items(), key=lambda x: x[1], reverse=True):
        print(f"   {regime:20s}: {count:3d} decisions")
    
    # Strategy distribution
    strategy_dist = get_strategy_distribution(q_table)
    print(f"\nğŸ¯ Strategy Distribution:")
    for strategy, count in sorted(strategy_dist.items(), key=lambda x: x[1], reverse=True):
        print(f"   {strategy:25s}: {count:3d} decisions")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # SECTION 3: TOP PERFORMING STRATEGIES
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print_section("3. Top Performing Strategies (by EMA Reward)")
    
    summary = integration.get_performance_summary()
    best_strategies = summary.get("best_strategies", [])
    
    if not best_strategies:
        print("âŒ No performance data yet")
    else:
        print(f"{'Rank':<5} {'Symbol':<12} {'Regime':<15} {'Strategy':<25} {'EMA R':<8} {'WR':<6} {'N':<4} {'Total R':<8}")
        print("â”€" * 120)
        
        for i, strat in enumerate(best_strategies[:20], 1):
            symbol = strat['symbol']
            regime = strat['regime']
            strategy = strat['strategy']
            ema_r = strat['ema_reward']
            wr = strat['win_rate']
            n = strat['count']
            total_r = strat['total_r']
            
            # Color coding
            if ema_r > 2.0:
                emoji = "ğŸ†"
            elif ema_r > 1.0:
                emoji = "âœ…"
            elif ema_r > 0:
                emoji = "âš ï¸ "
            else:
                emoji = "âŒ"
            
            print(f"{emoji} {i:<3} {symbol:<12} {regime:<15} {strategy:<25} {ema_r:>+6.2f}R {wr:>5.0%} {n:>3} {total_r:>+7.1f}R")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # SECTION 4: LEARNING METRICS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print_section("4. Learning Metrics")
    
    # Calculate actual exploration rate
    if metrics['total_selections'] > 0:
        # Note: We don't track exploration/exploitation separately yet, so estimate
        print(f"Configured Epsilon: {metrics['epsilon']:.0%}")
        print(f"Expected Exploration Rate: ~{metrics['epsilon']:.0%}")
        print(f"Expected Exploitation Rate: ~{1-metrics['epsilon']:.0%}")
    
    # Count strategies with sufficient data
    strategies_with_data = sum(1 for stats in q_table.values() if stats.count >= 5)
    print(f"\nStrategies with â‰¥5 samples: {strategies_with_data}/{len(q_table)}")
    
    # Calculate average EMA reward
    ema_rewards = [stats.ema_reward for stats in q_table.values() if stats.count >= 3]
    if ema_rewards:
        import statistics
        mean_ema = statistics.mean(ema_rewards)
        median_ema = statistics.median(ema_rewards)
        stdev_ema = statistics.stdev(ema_rewards) if len(ema_rewards) > 1 else 0
        
        print(f"\nEMA Reward Statistics (N={len(ema_rewards)}):")
        print(f"   Mean:   {mean_ema:+.2f}R")
        print(f"   Median: {median_ema:+.2f}R")
        print(f"   StdDev: {stdev_ema:.2f}R")
        print(f"   CV:     {stdev_ema/abs(mean_ema):.2f}" if mean_ema != 0 else "   CV:     N/A")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # SECTION 5: RECOMMENDATIONS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print_section("5. Parameter Tuning Recommendations")
    
    # Exploration rate recommendation
    print("ğŸ” Exploration Rate (Epsilon):")
    exploration_rec = analyze_exploration_rate(metrics)
    print(f"   {exploration_rec}")
    
    # Learning stability recommendation
    print("\nğŸ“Š Learning Stability (Alpha):")
    stability_rec = analyze_learning_stability(q_table)
    print(f"   {stability_rec}")
    
    # Convergence analysis
    print("\nğŸ“ˆ Convergence Status:")
    total_updates = metrics['total_reward_updates']
    
    if total_updates < 20:
        print("   â³ Cold Start Phase (< 20 updates)")
        print("      â†’ Keep current parameters")
        print("      â†’ Wait for 20+ trades to complete")
    elif total_updates < 50:
        print("   ğŸ”„ Learning Phase (20-50 updates)")
        print("      â†’ Monitor Q-values weekly")
        print("      â†’ Watch for strategy patterns")
    elif total_updates < 100:
        print("   ğŸ“Š Convergence Phase (50-100 updates)")
        print("      â†’ Strategies should be emerging")
        print("      â†’ Consider reducing epsilon to 0.05")
    else:
        print("   âœ… Mature Phase (100+ updates)")
        print("      â†’ System has learned optimal strategies")
        print("      â†’ Fine-tune epsilon (0.03-0.05) for exploitation")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # SECTION 6: REGIME-SPECIFIC ANALYSIS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print_section("6. Regime-Specific Best Strategies")
    
    # Group by regime and find best strategy per regime
    regime_best = {}
    for key, stats in q_table.items():
        symbol, regime, strategy = key
        if stats.count < 3:  # Skip insufficient data
            continue
        
        if regime not in regime_best:
            regime_best[regime] = []
        regime_best[regime].append({
            "strategy": strategy,
            "ema_reward": stats.ema_reward,
            "count": stats.count,
            "win_rate": stats.get_win_rate()
        })
    
    for regime in sorted(regime_best.keys()):
        strategies = sorted(regime_best[regime], key=lambda x: x["ema_reward"], reverse=True)
        best = strategies[0] if strategies else None
        
        if best:
            print(f"\n{regime}:")
            print(f"   Best: {best['strategy']:25s} | EMA R={best['ema_reward']:+.2f} | WR={best['win_rate']:.0%} | N={best['count']}")
            
            if len(strategies) > 1:
                print(f"   Alternatives:")
                for alt in strategies[1:4]:  # Show top 3 alternatives
                    print(f"      â€¢ {alt['strategy']:25s} | EMA R={alt['ema_reward']:+.2f} | WR={alt['win_rate']:.0%} | N={alt['count']}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # SECTION 7: ACTION ITEMS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print_section("7. Recommended Actions")
    
    actions = []
    
    # Check if need to adjust epsilon
    if total_updates >= 50 and metrics['epsilon'] > 0.05:
        actions.append("âœ“ Reduce epsilon to 0.05 in .env (more exploitation)")
    
    # Check if need to adjust alpha
    if len(ema_rewards) >= 10:
        cv = stdev_ema / abs(mean_ema) if mean_ema != 0 else 0
        if cv > 0.5 and metrics['alpha'] > 0.15:
            actions.append("âœ“ Reduce alpha to 0.15 in .env (more stability)")
    
    # Check if ready for production
    if total_updates >= 100:
        actions.append("âœ“ System mature - ready for full production use")
    
    if not actions:
        actions.append("âœ“ No actions needed - continue monitoring")
    
    for action in actions:
        print(f"   {action}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # FOOTER
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\n" + "=" * 80)
    print(f"  Report Generated: {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')}")
    print(f"  Next Review: Run this script weekly for 4 weeks")
    print("=" * 80 + "\n")


if __name__ == "__main__":
    asyncio.run(main())
