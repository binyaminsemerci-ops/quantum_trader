"""
Train Ensemble Model with Real Historical Data
Downloads data from Binance and trains 6-model ensemble with advanced features
"""

import sys
import os
import asyncio
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import pickle

# Add paths
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

print("="*70)
print("ðŸš€ TRAINING ENSEMBLE MODEL WITH REAL HISTORICAL DATA")
print("="*70)

# ============================================================
# 1. FETCH HISTORICAL DATA FROM BINANCE
# ============================================================
print("\nðŸ“Š Step 1: Fetching historical data from Binance...")

try:
    import ccxt
    
    exchange = ccxt.binance({
        'enableRateLimit': True,
        'options': {'defaultType': 'spot'}
    })
    
    async def fetch_ohlcv_data(symbol: str, timeframe: str = '1h', limit: int = 1000):
        """Fetch OHLCV data from Binance"""
        print(f"   Fetching {symbol} {timeframe} data...")
        
        # Fetch data
        ohlcv = exchange.fetch_ohlcv(symbol, timeframe, limit=limit)
        
        # Convert to DataFrame
        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        
        print(f"   âœ… Fetched {len(df)} candles for {symbol}")
        return df
    
    # Fetch data for multiple symbols
    symbols = ['BTC/USDT', 'ETH/USDT']
    all_data = {}
    
    for symbol in symbols:
        df = fetch_ohlcv_data(symbol, timeframe='1h', limit=2000)
        all_data[symbol] = df
    
    # Combine data for training
    print(f"\n   Total data points: {sum(len(df) for df in all_data.values())}")
    
except Exception as e:
    print(f"   âŒ Error fetching data: {e}")
    print("   Using fallback: generating synthetic data...")
    
    # Fallback: Generate synthetic data
    dates = pd.date_range(end=datetime.now(), periods=2000, freq='1h')
    
    all_data = {}
    for symbol in ['BTC/USDT', 'ETH/USDT']:
        base_price = 50000 if 'BTC' in symbol else 3000
        
        # Generate realistic price movement
        returns = np.random.randn(2000) * 0.02  # 2% hourly volatility
        prices = base_price * np.exp(np.cumsum(returns))
        
        df = pd.DataFrame({
            'timestamp': dates,
            'open': prices,
            'high': prices * (1 + abs(np.random.randn(2000) * 0.01)),
            'low': prices * (1 - abs(np.random.randn(2000) * 0.01)),
            'close': prices * (1 + np.random.randn(2000) * 0.005),
            'volume': np.random.randint(100, 1000, 2000)
        })
        
        all_data[symbol] = df
    
    print(f"   âœ… Generated {sum(len(df) for df in all_data.values())} synthetic data points")

# ============================================================
# 2. FEATURE ENGINEERING WITH ADVANCED FEATURES
# ============================================================
print("\nðŸ”§ Step 2: Engineering features (100+ indicators)...")

try:
    from ai_engine.feature_engineer_advanced import add_advanced_features
    from ai_engine.feature_engineer import compute_all_indicators
    
    all_features = []
    
    for symbol, df in all_data.items():
        print(f"   Processing {symbol}...")
        
        # Add advanced features
        df_features = add_advanced_features(df)
        
        # Add target (next hour return)
        df_features['target'] = df_features['close'].pct_change(1).shift(-1)
        
        # Drop rows with NaN
        df_features = df_features.dropna()
        
        all_features.append(df_features)
        print(f"      âœ… {len(df_features.columns)} features, {len(df_features)} samples")
    
    # Combine all data
    combined_df = pd.concat(all_features, axis=0, ignore_index=True)
    print(f"\n   âœ… Total training data: {len(combined_df)} samples, {len(combined_df.columns)} features")
    
except Exception as e:
    print(f"   âŒ Feature engineering error: {e}")
    sys.exit(1)

# ============================================================
# 3. PREPARE TRAINING DATA
# ============================================================
print("\nðŸ“¦ Step 3: Preparing training/validation split...")

try:
    # Select numeric features only
    feature_cols = combined_df.select_dtypes(include=[np.number]).columns.tolist()
    feature_cols.remove('target')
    
    X = combined_df[feature_cols].values
    y = combined_df['target'].values
    
    # Remove infinite values
    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)
    y = np.nan_to_num(y, nan=0.0, posinf=0.0, neginf=0.0)
    
    # Train/validation split (80/20)
    split_idx = int(len(X) * 0.8)
    X_train, X_val = X[:split_idx], X[split_idx:]
    y_train, y_val = y[:split_idx], y[split_idx:]
    
    print(f"   Training set: {X_train.shape}")
    print(f"   Validation set: {X_val.shape}")
    print(f"   Features: {len(feature_cols)}")
    
    # Standardize features
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_val_scaled = scaler.transform(X_val)
    
    print(f"   âœ… Data prepared and scaled")
    
except Exception as e:
    print(f"   âŒ Data preparation error: {e}")
    sys.exit(1)

# ============================================================
# 4. TRAIN ENSEMBLE MODEL
# ============================================================
print("\nðŸ¤– Step 4: Training ensemble model (this may take 2-5 minutes)...")

try:
    from ai_engine.model_ensemble import create_ensemble
    
    # Create and train ensemble
    ensemble = create_ensemble()
    ensemble.fit(X_train_scaled, y_train, X_val_scaled, y_val)
    
    # Save ensemble model to correct location
    model_path = "ai_engine/models/ensemble_model.pkl"
    os.makedirs(os.path.dirname(model_path), exist_ok=True)
    ensemble.save(model_path)
    
    # Save scaler
    scaler_path = "ai_engine/models/scaler.pkl"
    with open(scaler_path, 'wb') as f:
        pickle.dump(scaler, f)
    
    print(f"\n   âœ… Models saved:")
    print(f"      - ai_engine/models/ensemble_model.pkl")
    print(f"      - ai_engine/models/scaler.pkl")
    
except Exception as e:
    print(f"   âŒ Training error: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# ============================================================
# 5. EVALUATE MODEL PERFORMANCE
# ============================================================
print("\nðŸ“Š Step 5: Evaluating model performance...")

try:
    from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
    
    # Get predictions with confidence
    predictions, confidence = ensemble.predict_with_confidence(X_val_scaled)
    
    # Calculate metrics
    r2 = r2_score(y_val, predictions)
    mae = mean_absolute_error(y_val, predictions)
    rmse = np.sqrt(mean_squared_error(y_val, predictions))
    
    # Directional accuracy (did we predict direction correctly?)
    pred_direction = np.sign(predictions)
    true_direction = np.sign(y_val)
    directional_accuracy = np.mean(pred_direction == true_direction)
    
    print(f"\n   Performance Metrics:")
    print(f"   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print(f"   RÂ² Score:              {r2:.4f}")
    print(f"   Mean Absolute Error:   {mae:.6f}")
    print(f"   Root Mean Squared:     {rmse:.6f}")
    print(f"   Directional Accuracy:  {directional_accuracy:.2%}")
    print(f"   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    # Sample predictions
    print(f"\n   Sample Predictions (first 10):")
    print(f"   {'True':>10s} {'Predicted':>10s} {'Confidence':>10s} {'Direction':>10s}")
    print(f"   {'-'*44}")
    for i in range(min(10, len(y_val))):
        true_val = y_val[i]
        pred_val = predictions[i]
        conf = confidence[i]
        correct = 'âœ…' if np.sign(true_val) == np.sign(pred_val) else 'âŒ'
        print(f"   {true_val:>10.6f} {pred_val:>10.6f} {conf:>10.2f} {correct:>10s}")
    
    # Feature importance
    importance_df = ensemble.get_feature_importance(feature_cols)
    if not importance_df.empty:
        print(f"\n   Top 10 Most Important Features:")
        print(f"   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        for idx, row in importance_df.head(10).iterrows():
            print(f"   {row['feature']:30s}: {row['importance']:.4f}")
    
except Exception as e:
    print(f"   âŒ Evaluation error: {e}")

# ============================================================
# 6. TEST PREDICTION ON NEW DATA
# ============================================================
print("\nðŸŽ¯ Step 6: Testing prediction on latest data...")

try:
    # Get latest data
    latest_symbol = 'BTC/USDT'
    latest_df = all_data[latest_symbol].tail(100).copy()
    
    # Add features
    latest_features = add_advanced_features(latest_df)
    
    # Get last row features
    X_latest = latest_features[feature_cols].iloc[-1:].values
    X_latest = np.nan_to_num(X_latest, nan=0.0, posinf=0.0, neginf=0.0)
    X_latest_scaled = scaler.transform(X_latest)
    
    # Predict
    pred, conf = ensemble.predict_with_confidence(X_latest_scaled)
    
    current_price = latest_df['close'].iloc[-1]
    predicted_return = pred[0]
    predicted_price = current_price * (1 + predicted_return)
    
    action = 'BUY' if predicted_return > 0.002 else 'SELL' if predicted_return < -0.002 else 'HOLD'
    
    print(f"\n   Latest Prediction for {latest_symbol}:")
    print(f"   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print(f"   Current Price:      ${current_price:,.2f}")
    print(f"   Predicted Return:   {predicted_return:.4%}")
    print(f"   Predicted Price:    ${predicted_price:,.2f}")
    print(f"   Confidence:         {conf[0]:.2f}")
    print(f"   Recommendation:     {action}")
    print(f"   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
except Exception as e:
    print(f"   âš ï¸  Prediction test error: {e}")

# ============================================================
# SUMMARY
# ============================================================
print("\n" + "="*70)
print("âœ… ENSEMBLE MODEL TRAINING COMPLETE!")
print("="*70)
print("\nModel Details:")
print(f"   - 6 models: XGBoost, LightGBM, CatBoost, RF, GB, MLP")
print(f"   - Features: {len(feature_cols)} advanced indicators")
print(f"   - Training samples: {len(X_train)}")
print(f"   - Validation RÂ²: {r2:.4f}")
print(f"   - Directional accuracy: {directional_accuracy:.2%}")
print("\nNext Steps:")
print("   1. âœ… Model trained and saved")
print("   2. ðŸ”œ Run backtest: python backtest_with_improvements.py")
print("   3. ðŸ”œ Integrate with live trading system")
print("="*70)
