#!/usr/bin/env python3
"""
Sjekker LÃ†RNING og TRENING status for alle AI moduler
"""
import os
import sys
import json
from datetime import datetime, timedelta

# Add backend to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "backend"))

print("\n" + "="*80)
print("ğŸ“š AI LÃ†RNING & TRENING STATUS")
print("="*80 + "\n")

# Check database for training samples
try:
    from backend.database import SessionLocal
    from backend.models.ai_training import AITrainingSample, AIModelVersion
    
    db = SessionLocal()
    
    print("ğŸ“Š TRAINING DATA STATUS:")
    print("-" * 80)
    
    # Count total samples
    total_samples = db.query(AITrainingSample).count()
    print(f"\nâœ… Total training samples recorded: {total_samples}")
    
    # Count samples with known outcomes
    completed_samples = db.query(AITrainingSample).filter(
        AITrainingSample.outcome_known == True
    ).count()
    print(f"âœ… Samples with known outcomes: {completed_samples}")
    
    # Count pending samples
    pending_samples = db.query(AITrainingSample).filter(
        AITrainingSample.outcome_known == False
    ).count()
    print(f"â³ Pending samples (waiting for outcome): {pending_samples}")
    
    # Recent samples (last 24 hours)
    yesterday = datetime.utcnow() - timedelta(days=1)
    recent_samples = db.query(AITrainingSample).filter(
        AITrainingSample.timestamp >= yesterday
    ).count()
    print(f"ğŸ“ˆ New samples (last 24h): {recent_samples}")
    
    print("\n" + "-" * 80)
    print("ğŸ¤– MODEL VERSIONS:")
    print("-" * 80 + "\n")
    
    # Check model versions
    model_versions = db.query(AIModelVersion).order_by(
        AIModelVersion.trained_at.desc()
    ).limit(5).all()
    
    if model_versions:
        print(f"âœ… Found {len(model_versions)} model version(s):\n")
        for mv in model_versions:
            print(f"Model: {mv.model_type} v{mv.version_id}")
            print(f"  Trained: {mv.trained_at}")
            print(f"  Training samples: {mv.training_samples}")
            if mv.validation_accuracy:
                print(f"  Validation accuracy: {mv.validation_accuracy:.2%}")
            print()
    else:
        print("âš ï¸  No model versions recorded yet")
    
    db.close()
    
except Exception as e:
    print(f"âš ï¸  Database check failed: {e}")
    print("   (This is normal if database is not set up)")

print("\n" + "="*80)
print("ğŸ§  RL AGENT LEARNING STATUS:")
print("="*80 + "\n")

# Check RL agent state file
rl_state_file = "rl_position_sizing_state.json"
if os.path.exists(rl_state_file):
    try:
        with open(rl_state_file, 'r') as f:
            rl_state = json.load(f)
        
        q_table = rl_state.get('q_table', {})
        total_trades = rl_state.get('total_trades', 0)
        successful_trades = rl_state.get('successful_trades', 0)
        failed_trades = rl_state.get('failed_trades', 0)
        exploration_rate = rl_state.get('exploration_rate', 0.0)
        
        print(f"âœ… RL Agent State File: {rl_state_file}")
        print(f"\nğŸ“Š Learning Progress:")
        print(f"   Total trades: {total_trades}")
        print(f"   Successful: {successful_trades}")
        print(f"   Failed: {failed_trades}")
        if total_trades > 0:
            win_rate = successful_trades / total_trades * 100
            print(f"   Win rate: {win_rate:.1f}%")
        print(f"   Exploration rate: {exploration_rate:.2%}")
        print(f"\nğŸ§  Q-Table size: {len(q_table)} states learned")
        
        if q_table:
            print(f"\n   Sample Q-values (first 5 states):")
            for i, (state, q_vals) in enumerate(list(q_table.items())[:5]):
                best_action = max(q_vals, key=q_vals.get)
                best_q = q_vals[best_action]
                print(f"   {i+1}. State {state[:50]}...")
                print(f"      Best action: {best_action} (Q={best_q:.3f})")
        
    except Exception as e:
        print(f"âš ï¸  Failed to read RL state: {e}")
else:
    print(f"âš ï¸  RL state file not found: {rl_state_file}")

print("\n" + "="*80)
print("ğŸ“ˆ ENSEMBLE MODELS TRAINING:")
print("="*80 + "\n")

# Check for model files
models_dir = "models"
if os.path.exists(models_dir):
    model_files = [
        "xgboost_ensemble.pkl",
        "lightgbm_ensemble.pkl", 
        "n_hits_ensemble.pt",
        "patchtst_ensemble.pt"
    ]
    
    for model_file in model_files:
        model_path = os.path.join(models_dir, model_file)
        if os.path.exists(model_path):
            stat = os.stat(model_path)
            mod_time = datetime.fromtimestamp(stat.st_mtime)
            size_mb = stat.st_size / (1024 * 1024)
            age = datetime.now() - mod_time
            
            print(f"âœ… {model_file}")
            print(f"   Size: {size_mb:.1f} MB")
            print(f"   Last modified: {mod_time.strftime('%Y-%m-%d %H:%M')}")
            print(f"   Age: {age.days} days, {age.seconds // 3600} hours")
            
            if age.days > 30:
                print(f"   âš ï¸  MODEL GAMMEL! BÃ¸r re-trenes med fersk data")
            elif age.days > 7:
                print(f"   âš ï¸  Kan trenge oppdatering snart")
            else:
                print(f"   âœ… Relativt fersk")
            print()
    
    print(f"\nğŸ’¡ MODEL STATUS:")
    print(f"   Alle modeller er PRE-TRAINED (trent fÃ¸r testnet)")
    print(f"   De genererer predictions MEN lÃ¦rer ikke automatisk ennÃ¥")
    print(f"   For CONTINUOUS LEARNING mÃ¥ retraining aktiveres")
else:
    print(f"âš ï¸  Models directory not found: {models_dir}")

print("\n" + "="*80)
print("ğŸ¯ RETRAINING ORCHESTRATOR:")
print("="*80 + "\n")

# Check if retraining orchestrator is configured
retraining_file = "backend/services/retraining_orchestrator.py"
if os.path.exists(retraining_file):
    stat = os.stat(retraining_file)
    size_kb = stat.st_size / 1024
    print(f"âœ… Retraining Orchestrator exists: {size_kb:.1f} KB")
    print(f"   Features:")
    print(f"   â€¢ Automatic model retraining based on performance drift")
    print(f"   â€¢ Scheduled periodic retraining")
    print(f"   â€¢ Regime-change triggered retraining")
    print(f"   â€¢ Model versioning & rollback capabilities")
    print(f"   â€¢ Safe deployment with canary testing")
    print(f"\n   âš ï¸  STATUS: Implementert men IKKE aktivert ennÃ¥")
    print(f"   ğŸ“ Krever: Database setup + trigger configuration")
else:
    print(f"âš ï¸  Retraining orchestrator not found")

print("\n" + "="*80)
print("ğŸ“‹ SAMMENDRAG - LÃ†RNING & TRENING:")
print("="*80 + "\n")

print("âœ… FUNGERER NÃ…:")
print("   1. Math AI - Beregner optimale parametere (AKTIV)")
print("   2. RL Agent - LÃ¦rer fra 85 historical trades via Q-learning")
print("   3. Training data collection - Samler features + outcomes")
print("   4. Ensemble models - Genererer predictions (pre-trained)")
print()

print("âš ï¸  MANGLER AUTOMATISERING:")
print("   1. Continuous model retraining - MÃ¥ aktiveres manuelt")
print("   2. Ensemble models lÃ¦rer ikke automatisk fra nye data")
print("   3. Models er PRE-TRAINED, ikke re-trent pÃ¥ testnet data")
print("   4. Retraining orchestrator implementert men ikke aktivert")
print()

print("ğŸ¯ NESTE STEG FOR FULL AUTONOMOUS LEARNING:")
print("   1. Aktivere retraining orchestrator")
print("   2. Configure retraining triggers (performance/schedule/drift)")
print("   3. Setup automatic model deployment pipeline")
print("   4. Enable continuous feedback loop:")
print("      Predictions â†’ Execution â†’ Outcome â†’ Training Data â†’ Retrain â†’ Better Predictions")
print()

print("ğŸ’¡ KONKLUSJON:")
print("   â€¢ RL Agent lÃ¦rer aktivt fra hver trade (âœ… ONLINE LEARNING)")
print("   â€¢ Ensemble models bruker pre-trained weights (âš ï¸  OFFLINE, kan re-trenes)")
print("   â€¢ Math AI trenger ikke training (âœ… RULE-BASED, alltid optimal)")
print("   â€¢ System samler training data men re-trainer ikke automatisk ennÃ¥")
print()
print("   For Ã¥ aktivere FULL continuous learning, mÃ¥ retraining system startes!")
print()
print("="*80 + "\n")
