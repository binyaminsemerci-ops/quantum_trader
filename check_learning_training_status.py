#!/usr/bin/env python3
"""
Sjekker L√ÜRNING og TRENING status for alle AI moduler
"""
import os
import sys
import json
from datetime import datetime, timedelta

# Add backend to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "backend"))

print("\n" + "="*80)
print("üìö AI L√ÜRNING & TRENING STATUS")
print("="*80 + "\n")

# Check database for training samples
try:
    from backend.database import SessionLocal
    from backend.models.ai_training import AITrainingSample, AIModelVersion
    
    db = SessionLocal()
    
    print("üìä TRAINING DATA STATUS:")
    print("-" * 80)
    
    # Count total samples
    total_samples = db.query(AITrainingSample).count()
    print(f"\n‚úÖ Total training samples recorded: {total_samples}")
    
    # Count samples with known outcomes
    completed_samples = db.query(AITrainingSample).filter(
        AITrainingSample.outcome_known == True
    ).count()
    print(f"‚úÖ Samples with known outcomes: {completed_samples}")
    
    # Count pending samples
    pending_samples = db.query(AITrainingSample).filter(
        AITrainingSample.outcome_known == False
    ).count()
    print(f"‚è≥ Pending samples (waiting for outcome): {pending_samples}")
    
    # Recent samples (last 24 hours)
    yesterday = datetime.utcnow() - timedelta(days=1)
    recent_samples = db.query(AITrainingSample).filter(
        AITrainingSample.timestamp >= yesterday
    ).count()
    print(f"üìà New samples (last 24h): {recent_samples}")
    
    print("\n" + "-" * 80)
    print("ü§ñ MODEL VERSIONS:")
    print("-" * 80 + "\n")
    
    # Check model versions
    model_versions = db.query(AIModelVersion).order_by(
        AIModelVersion.trained_at.desc()
    ).limit(5).all()
    
    if model_versions:
        print(f"‚úÖ Found {len(model_versions)} model version(s):\n")
        for mv in model_versions:
            print(f"Model: {mv.model_type} v{mv.version_id}")
            print(f"  Trained: {mv.trained_at}")
            print(f"  Training samples: {mv.training_samples}")
            if mv.validation_accuracy:
                print(f"  Validation accuracy: {mv.validation_accuracy:.2%}")
            print()
    else:
        print("‚ö†Ô∏è  No model versions recorded yet")
    
    db.close()
    
except Exception as e:
    print(f"‚ö†Ô∏è  Database check failed: {e}")
    print("   (This is normal if database is not set up)")

print("\n" + "="*80)
print("üß† RL AGENT LEARNING STATUS:")
print("="*80 + "\n")

# Check RL agent state file
rl_state_file = "rl_position_sizing_state.json"
if os.path.exists(rl_state_file):
    try:
        with open(rl_state_file, 'r') as f:
            rl_state = json.load(f)
        
        q_table = rl_state.get('q_table', {})
        total_trades = rl_state.get('total_trades', 0)
        successful_trades = rl_state.get('successful_trades', 0)
        failed_trades = rl_state.get('failed_trades', 0)
        exploration_rate = rl_state.get('exploration_rate', 0.0)
        
        print(f"‚úÖ RL Agent State File: {rl_state_file}")
        print(f"\nüìä Learning Progress:")
        print(f"   Total trades: {total_trades}")
        print(f"   Successful: {successful_trades}")
        print(f"   Failed: {failed_trades}")
        if total_trades > 0:
            win_rate = successful_trades / total_trades * 100
            print(f"   Win rate: {win_rate:.1f}%")
        print(f"   Exploration rate: {exploration_rate:.2%}")
        print(f"\nüß† Q-Table size: {len(q_table)} states learned")
        
        if q_table:
            print(f"\n   Sample Q-values (first 5 states):")
            for i, (state, q_vals) in enumerate(list(q_table.items())[:5]):
                best_action = max(q_vals, key=q_vals.get)
                best_q = q_vals[best_action]
                print(f"   {i+1}. State {state[:50]}...")
                print(f"      Best action: {best_action} (Q={best_q:.3f})")
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Failed to read RL state: {e}")
else:
    print(f"‚ö†Ô∏è  RL state file not found: {rl_state_file}")

print("\n" + "="*80)
print("üìà ENSEMBLE MODELS TRAINING:")
print("="*80 + "\n")

# Check for model files
models_dir = "models"
if os.path.exists(models_dir):
    model_files = [
        "xgboost_ensemble.pkl",
        "lightgbm_ensemble.pkl", 
        "n_hits_ensemble.pt",
        "patchtst_ensemble.pt"
    ]
    
    for model_file in model_files:
        model_path = os.path.join(models_dir, model_file)
        if os.path.exists(model_path):
            stat = os.stat(model_path)
            mod_time = datetime.fromtimestamp(stat.st_mtime)
            size_mb = stat.st_size / (1024 * 1024)
            age = datetime.now() - mod_time
            
            print(f"‚úÖ {model_file}")
            print(f"   Size: {size_mb:.1f} MB")
            print(f"   Last modified: {mod_time.strftime('%Y-%m-%d %H:%M')}")
            print(f"   Age: {age.days} days, {age.seconds // 3600} hours")
            
            if age.days > 30:
                print(f"   ‚ö†Ô∏è  MODEL GAMMEL! B√∏r re-trenes med fersk data")
            elif age.days > 7:
                print(f"   ‚ö†Ô∏è  Kan trenge oppdatering snart")
            else:
                print(f"   ‚úÖ Relativt fersk")
            print()
    
    print(f"\nüí° MODEL STATUS:")
    print(f"   Alle modeller er PRE-TRAINED (trent f√∏r testnet)")
    print(f"   De genererer predictions MEN l√¶rer ikke automatisk enn√•")
    print(f"   For CONTINUOUS LEARNING m√• retraining aktiveres")
else:
    print(f"‚ö†Ô∏è  Models directory not found: {models_dir}")

print("\n" + "="*80)
print("üéØ RETRAINING ORCHESTRATOR:")
print("="*80 + "\n")

# Check if retraining orchestrator is configured
retraining_file = "backend/services/retraining_orchestrator.py"
if os.path.exists(retraining_file):
    stat = os.stat(retraining_file)
    size_kb = stat.st_size / 1024
    print(f"‚úÖ Retraining Orchestrator exists: {size_kb:.1f} KB")
    print(f"   Features:")
    print(f"   ‚Ä¢ Automatic model retraining based on performance drift")
    print(f"   ‚Ä¢ Scheduled periodic retraining")
    print(f"   ‚Ä¢ Regime-change triggered retraining")
    print(f"   ‚Ä¢ Model versioning & rollback capabilities")
    print(f"   ‚Ä¢ Safe deployment with canary testing")
    print(f"\n   ‚ö†Ô∏è  STATUS: Implementert men IKKE aktivert enn√•")
    print(f"   üìù Krever: Database setup + trigger configuration")
else:
    print(f"‚ö†Ô∏è  Retraining orchestrator not found")

print("\n" + "="*80)
print("üìã SAMMENDRAG - L√ÜRNING & TRENING:")
print("="*80 + "\n")

print("‚úÖ FUNGERER N√Ö:")
print("   1. Math AI - Beregner optimale parametere (AKTIV)")
print("   2. RL Agent - L√¶rer fra 85 historical trades via Q-learning")
print("   3. Training data collection - Samler features + outcomes")
print("   4. Ensemble models - Genererer predictions (pre-trained)")
print()

print("‚ö†Ô∏è  MANGLER AUTOMATISERING:")
print("   1. Continuous model retraining - M√• aktiveres manuelt")
print("   2. Ensemble models l√¶rer ikke automatisk fra nye data")
print("   3. Models er PRE-TRAINED, ikke re-trent p√• testnet data")
print("   4. Retraining orchestrator implementert men ikke aktivert")
print()

print("üéØ NESTE STEG FOR FULL AUTONOMOUS LEARNING:")
print("   1. Aktivere retraining orchestrator")
print("   2. Configure retraining triggers (performance/schedule/drift)")
print("   3. Setup automatic model deployment pipeline")
print("   4. Enable continuous feedback loop:")
print("      Predictions ‚Üí Execution ‚Üí Outcome ‚Üí Training Data ‚Üí Retrain ‚Üí Better Predictions")
print()

print("üí° KONKLUSJON:")
print("   ‚Ä¢ RL Agent l√¶rer aktivt fra hver trade (‚úÖ ONLINE LEARNING)")
print("   ‚Ä¢ Ensemble models bruker pre-trained weights (‚ö†Ô∏è  OFFLINE, kan re-trenes)")
print("   ‚Ä¢ Math AI trenger ikke training (‚úÖ RULE-BASED, alltid optimal)")
print("   ‚Ä¢ System samler training data men re-trainer ikke automatisk enn√•")
print()
print("   For √• aktivere FULL continuous learning, m√• retraining system startes!")
print()
print("="*80 + "\n")
